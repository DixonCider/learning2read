{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import learning2read\n",
    "learning2read.reload_all()\n",
    "from learning2read.b05 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = Data('btrain')\n",
    "raw_test = Data('btest')\n",
    "raw_implicit = Data('implicit')\n",
    "raw_user = Data('user')\n",
    "raw_book = Data('book')\n",
    "raw_dataset = {\n",
    "    'raw_train' : raw_train,\n",
    "    'raw_test' : raw_test,\n",
    "    'raw_implicit' : raw_implicit,\n",
    "    'raw_user' : raw_user,\n",
    "    'raw_book' : raw_book,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = learning2read.preprocessing.TotalDataFrame.run([raw_train, raw_test, raw_implicit])['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "User-ID\n",
       "188ec05cf3    13602\n",
       "58a34dcfe5     7550\n",
       "91a5b876c9     6109\n",
       "997dc62862     5891\n",
       "67a302acdf     5850\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg_user=df_total.groupby('User-ID')\n",
    "gdf_user=dfg_user.agg({'Book-Rating':['count','min','max']})\n",
    "gdf_user.columns=['count','min','max'] # cancel multilevel index\n",
    "gdf_user_gte10=gdf_user.loc[gdf_user['count']>=1000,'count'].sort_values(ascending=False)\n",
    "print(len(gdf_user_gte10))\n",
    "gdf_user_gte10[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143511, 117)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_book=df_total.groupby('ISBN').agg({'User-ID':'count'})\n",
    "gdf_book.columns=['count']\n",
    "gdf_book=gdf_book.loc[gdf_book['count']>=2,:] # cut\n",
    "# gdf_book=gdf_book.loc[gdf_book['count']>=300,:] # cut2\n",
    "gdf_book=gdf_book.sort_values('count',ascending=False)\n",
    "dim1=len(gdf_book.index)\n",
    "dim2=len(gdf_user_gte10.index)\n",
    "dim1,dim2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "user_vector_id = defaultdict(lambda: -1)\n",
    "book_id = defaultdict(lambda: -1)\n",
    "i=0\n",
    "for x in gdf_user_gte10.index:\n",
    "    user_vector_id[x] = i\n",
    "    i+=1\n",
    "i=0\n",
    "for x in gdf_book.index:\n",
    "    book_id[x]=i\n",
    "    i+=1\n",
    "\n",
    "index_list = []\n",
    "for r in df_total.to_dict('record'):\n",
    "    uid = user_vector_id[r['User-ID']]\n",
    "    bid = book_id[r['ISBN']]\n",
    "    if uid>=0 and bid>=0:\n",
    "        index_list.append([bid,uid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing CLI arguements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='VAE MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for training (default: 128)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=True,\n",
    "                    help='enables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "args = parser.parse_args([])\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "# Sets the seed for generating random numbers. Returns a torch._C.Generator object.\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_tns=torch.LongTensor(index_list).t()\n",
    "value_tns=torch.ones(index_tns.size(1))\n",
    "train_tns=torch.sparse.FloatTensor(index_tns, value_tns, torch.Size([dim1,dim2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tns=train_tns.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([143511, 117])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tns.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookVectorData(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``processed/training.pt``\n",
    "            and  ``processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_features):\n",
    "        self.train_features = train_features\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: target_data[index]\n",
    "        \"\"\"\n",
    "        target = self.train_features[index]\n",
    "        return target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BookVectorData(train_tns)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import datetime\n",
    "now=datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(117, 64)\n",
    "        self.fc21 = nn.Linear(64, 16)\n",
    "        self.fc22 = nn.Linear(64, 16)\n",
    "        self.fc3 = nn.Linear(16, 64)\n",
    "        self.fc4 = nn.Linear(64, 117)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return F.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 117))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 117), size_average=False)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/143511 (0%)]\tLoss: 83.534233\n",
      "Train Epoch: 1 [1280/143511 (1%)]\tLoss: 73.687332\n",
      "Train Epoch: 1 [2560/143511 (2%)]\tLoss: 64.140427\n",
      "Train Epoch: 1 [3840/143511 (3%)]\tLoss: 54.942703\n",
      "Train Epoch: 1 [5120/143511 (4%)]\tLoss: 43.331375\n",
      "Train Epoch: 1 [6400/143511 (4%)]\tLoss: 33.082108\n",
      "Train Epoch: 1 [7680/143511 (5%)]\tLoss: 24.876284\n",
      "Train Epoch: 1 [8960/143511 (6%)]\tLoss: 21.853683\n",
      "Train Epoch: 1 [10240/143511 (7%)]\tLoss: 15.293964\n",
      "Train Epoch: 1 [11520/143511 (8%)]\tLoss: 12.673884\n",
      "Train Epoch: 1 [12800/143511 (9%)]\tLoss: 14.842859\n",
      "Train Epoch: 1 [14080/143511 (10%)]\tLoss: 13.294661\n",
      "Train Epoch: 1 [15360/143511 (11%)]\tLoss: 11.352051\n",
      "Train Epoch: 1 [16640/143511 (12%)]\tLoss: 10.108412\n",
      "Train Epoch: 1 [17920/143511 (12%)]\tLoss: 11.461728\n",
      "Train Epoch: 1 [19200/143511 (13%)]\tLoss: 10.398964\n",
      "Train Epoch: 1 [20480/143511 (14%)]\tLoss: 10.211489\n",
      "Train Epoch: 1 [21760/143511 (15%)]\tLoss: 8.846856\n",
      "Train Epoch: 1 [23040/143511 (16%)]\tLoss: 10.780325\n",
      "Train Epoch: 1 [24320/143511 (17%)]\tLoss: 9.394047\n",
      "Train Epoch: 1 [25600/143511 (18%)]\tLoss: 9.733102\n",
      "Train Epoch: 1 [26880/143511 (19%)]\tLoss: 9.136159\n",
      "Train Epoch: 1 [28160/143511 (20%)]\tLoss: 9.545467\n",
      "Train Epoch: 1 [29440/143511 (20%)]\tLoss: 10.174397\n",
      "Train Epoch: 1 [30720/143511 (21%)]\tLoss: 10.306580\n",
      "Train Epoch: 1 [32000/143511 (22%)]\tLoss: 8.959704\n",
      "Train Epoch: 1 [33280/143511 (23%)]\tLoss: 7.803174\n",
      "Train Epoch: 1 [34560/143511 (24%)]\tLoss: 8.636006\n",
      "Train Epoch: 1 [35840/143511 (25%)]\tLoss: 8.389821\n",
      "Train Epoch: 1 [37120/143511 (26%)]\tLoss: 8.384001\n",
      "Train Epoch: 1 [38400/143511 (27%)]\tLoss: 9.366717\n",
      "Train Epoch: 1 [39680/143511 (28%)]\tLoss: 7.736381\n",
      "Train Epoch: 1 [40960/143511 (29%)]\tLoss: 8.520065\n",
      "Train Epoch: 1 [42240/143511 (29%)]\tLoss: 7.736618\n",
      "Train Epoch: 1 [43520/143511 (30%)]\tLoss: 8.749237\n",
      "Train Epoch: 1 [44800/143511 (31%)]\tLoss: 7.686764\n",
      "Train Epoch: 1 [46080/143511 (32%)]\tLoss: 6.727576\n",
      "Train Epoch: 1 [47360/143511 (33%)]\tLoss: 9.066541\n",
      "Train Epoch: 1 [48640/143511 (34%)]\tLoss: 7.634139\n",
      "Train Epoch: 1 [49920/143511 (35%)]\tLoss: 8.925995\n",
      "Train Epoch: 1 [51200/143511 (36%)]\tLoss: 8.059026\n",
      "Train Epoch: 1 [52480/143511 (37%)]\tLoss: 7.805690\n",
      "Train Epoch: 1 [53760/143511 (37%)]\tLoss: 7.325422\n",
      "Train Epoch: 1 [55040/143511 (38%)]\tLoss: 7.599232\n",
      "Train Epoch: 1 [56320/143511 (39%)]\tLoss: 6.658503\n",
      "Train Epoch: 1 [57600/143511 (40%)]\tLoss: 7.279712\n",
      "Train Epoch: 1 [58880/143511 (41%)]\tLoss: 8.168217\n",
      "Train Epoch: 1 [60160/143511 (42%)]\tLoss: 6.309492\n",
      "Train Epoch: 1 [61440/143511 (43%)]\tLoss: 8.048371\n",
      "Train Epoch: 1 [62720/143511 (44%)]\tLoss: 6.412552\n",
      "Train Epoch: 1 [64000/143511 (45%)]\tLoss: 7.033451\n",
      "Train Epoch: 1 [65280/143511 (45%)]\tLoss: 6.433843\n",
      "Train Epoch: 1 [66560/143511 (46%)]\tLoss: 6.445822\n",
      "Train Epoch: 1 [67840/143511 (47%)]\tLoss: 7.616015\n",
      "Train Epoch: 1 [69120/143511 (48%)]\tLoss: 8.064981\n",
      "Train Epoch: 1 [70400/143511 (49%)]\tLoss: 5.958337\n",
      "Train Epoch: 1 [71680/143511 (50%)]\tLoss: 8.117095\n",
      "Train Epoch: 1 [72960/143511 (51%)]\tLoss: 7.808920\n",
      "Train Epoch: 1 [74240/143511 (52%)]\tLoss: 7.030569\n",
      "Train Epoch: 1 [75520/143511 (53%)]\tLoss: 6.351542\n",
      "Train Epoch: 1 [76800/143511 (53%)]\tLoss: 6.318303\n",
      "Train Epoch: 1 [78080/143511 (54%)]\tLoss: 6.672043\n",
      "Train Epoch: 1 [79360/143511 (55%)]\tLoss: 7.180362\n",
      "Train Epoch: 1 [80640/143511 (56%)]\tLoss: 6.761055\n",
      "Train Epoch: 1 [81920/143511 (57%)]\tLoss: 8.859522\n",
      "Train Epoch: 1 [83200/143511 (58%)]\tLoss: 6.354765\n",
      "Train Epoch: 1 [84480/143511 (59%)]\tLoss: 7.983057\n",
      "Train Epoch: 1 [85760/143511 (60%)]\tLoss: 6.542397\n",
      "Train Epoch: 1 [87040/143511 (61%)]\tLoss: 5.870814\n",
      "Train Epoch: 1 [88320/143511 (61%)]\tLoss: 7.211531\n",
      "Train Epoch: 1 [89600/143511 (62%)]\tLoss: 6.536531\n",
      "Train Epoch: 1 [90880/143511 (63%)]\tLoss: 6.134860\n",
      "Train Epoch: 1 [92160/143511 (64%)]\tLoss: 5.072829\n",
      "Train Epoch: 1 [93440/143511 (65%)]\tLoss: 6.801094\n",
      "Train Epoch: 1 [94720/143511 (66%)]\tLoss: 6.385710\n",
      "Train Epoch: 1 [96000/143511 (67%)]\tLoss: 7.083799\n",
      "Train Epoch: 1 [97280/143511 (68%)]\tLoss: 6.236761\n",
      "Train Epoch: 1 [98560/143511 (69%)]\tLoss: 8.269720\n",
      "Train Epoch: 1 [99840/143511 (70%)]\tLoss: 7.607912\n",
      "Train Epoch: 1 [101120/143511 (70%)]\tLoss: 6.038610\n",
      "Train Epoch: 1 [102400/143511 (71%)]\tLoss: 5.890517\n",
      "Train Epoch: 1 [103680/143511 (72%)]\tLoss: 6.232856\n",
      "Train Epoch: 1 [104960/143511 (73%)]\tLoss: 6.000899\n",
      "Train Epoch: 1 [106240/143511 (74%)]\tLoss: 6.527479\n",
      "Train Epoch: 1 [107520/143511 (75%)]\tLoss: 5.715484\n",
      "Train Epoch: 1 [108800/143511 (76%)]\tLoss: 5.247284\n",
      "Train Epoch: 1 [110080/143511 (77%)]\tLoss: 6.162179\n",
      "Train Epoch: 1 [111360/143511 (78%)]\tLoss: 5.318910\n",
      "Train Epoch: 1 [112640/143511 (78%)]\tLoss: 6.900330\n",
      "Train Epoch: 1 [113920/143511 (79%)]\tLoss: 6.403114\n",
      "Train Epoch: 1 [115200/143511 (80%)]\tLoss: 5.866112\n",
      "Train Epoch: 1 [116480/143511 (81%)]\tLoss: 6.984377\n",
      "Train Epoch: 1 [117760/143511 (82%)]\tLoss: 6.026751\n",
      "Train Epoch: 1 [119040/143511 (83%)]\tLoss: 7.734819\n",
      "Train Epoch: 1 [120320/143511 (84%)]\tLoss: 6.596199\n",
      "Train Epoch: 1 [121600/143511 (85%)]\tLoss: 6.366009\n",
      "Train Epoch: 1 [122880/143511 (86%)]\tLoss: 5.307486\n",
      "Train Epoch: 1 [124160/143511 (86%)]\tLoss: 5.669546\n",
      "Train Epoch: 1 [125440/143511 (87%)]\tLoss: 6.692609\n",
      "Train Epoch: 1 [126720/143511 (88%)]\tLoss: 6.619913\n",
      "Train Epoch: 1 [128000/143511 (89%)]\tLoss: 6.623352\n",
      "Train Epoch: 1 [129280/143511 (90%)]\tLoss: 6.081597\n",
      "Train Epoch: 1 [130560/143511 (91%)]\tLoss: 7.800124\n",
      "Train Epoch: 1 [131840/143511 (92%)]\tLoss: 5.831234\n",
      "Train Epoch: 1 [133120/143511 (93%)]\tLoss: 6.289077\n",
      "Train Epoch: 1 [134400/143511 (94%)]\tLoss: 6.666006\n",
      "Train Epoch: 1 [135680/143511 (94%)]\tLoss: 6.343686\n",
      "Train Epoch: 1 [136960/143511 (95%)]\tLoss: 5.526380\n",
      "Train Epoch: 1 [138240/143511 (96%)]\tLoss: 7.025868\n",
      "Train Epoch: 1 [139520/143511 (97%)]\tLoss: 4.621066\n",
      "Train Epoch: 1 [140800/143511 (98%)]\tLoss: 7.619843\n",
      "Train Epoch: 1 [142080/143511 (99%)]\tLoss: 5.968166\n",
      "Train Epoch: 1 [143360/143511 (100%)]\tLoss: 5.461669\n",
      "====> Epoch: 1 Average loss: 10.2543\n",
      "Train Epoch: 2 [0/143511 (0%)]\tLoss: 5.430241\n",
      "Train Epoch: 2 [1280/143511 (1%)]\tLoss: 5.991660\n",
      "Train Epoch: 2 [2560/143511 (2%)]\tLoss: 7.452661\n",
      "Train Epoch: 2 [3840/143511 (3%)]\tLoss: 4.809340\n",
      "Train Epoch: 2 [5120/143511 (4%)]\tLoss: 6.635355\n",
      "Train Epoch: 2 [6400/143511 (4%)]\tLoss: 6.524877\n",
      "Train Epoch: 2 [7680/143511 (5%)]\tLoss: 6.476539\n",
      "Train Epoch: 2 [8960/143511 (6%)]\tLoss: 7.089261\n",
      "Train Epoch: 2 [10240/143511 (7%)]\tLoss: 5.831230\n",
      "Train Epoch: 2 [11520/143511 (8%)]\tLoss: 7.469343\n",
      "Train Epoch: 2 [12800/143511 (9%)]\tLoss: 5.630435\n",
      "Train Epoch: 2 [14080/143511 (10%)]\tLoss: 6.797594\n",
      "Train Epoch: 2 [15360/143511 (11%)]\tLoss: 6.900866\n",
      "Train Epoch: 2 [16640/143511 (12%)]\tLoss: 6.376458\n",
      "Train Epoch: 2 [17920/143511 (12%)]\tLoss: 6.528668\n",
      "Train Epoch: 2 [19200/143511 (13%)]\tLoss: 6.121373\n",
      "Train Epoch: 2 [20480/143511 (14%)]\tLoss: 6.031720\n",
      "Train Epoch: 2 [21760/143511 (15%)]\tLoss: 6.703475\n",
      "Train Epoch: 2 [23040/143511 (16%)]\tLoss: 6.479140\n",
      "Train Epoch: 2 [24320/143511 (17%)]\tLoss: 8.318672\n",
      "Train Epoch: 2 [25600/143511 (18%)]\tLoss: 5.524500\n",
      "Train Epoch: 2 [26880/143511 (19%)]\tLoss: 7.796621\n",
      "Train Epoch: 2 [28160/143511 (20%)]\tLoss: 7.522014\n",
      "Train Epoch: 2 [29440/143511 (20%)]\tLoss: 6.652987\n",
      "Train Epoch: 2 [30720/143511 (21%)]\tLoss: 5.217295\n",
      "Train Epoch: 2 [32000/143511 (22%)]\tLoss: 6.459653\n",
      "Train Epoch: 2 [33280/143511 (23%)]\tLoss: 6.641972\n",
      "Train Epoch: 2 [34560/143511 (24%)]\tLoss: 6.799891\n",
      "Train Epoch: 2 [35840/143511 (25%)]\tLoss: 6.353502\n",
      "Train Epoch: 2 [37120/143511 (26%)]\tLoss: 6.472115\n",
      "Train Epoch: 2 [38400/143511 (27%)]\tLoss: 6.676908\n",
      "Train Epoch: 2 [39680/143511 (28%)]\tLoss: 6.636334\n",
      "Train Epoch: 2 [40960/143511 (29%)]\tLoss: 4.939528\n",
      "Train Epoch: 2 [42240/143511 (29%)]\tLoss: 5.250015\n",
      "Train Epoch: 2 [43520/143511 (30%)]\tLoss: 6.797778\n",
      "Train Epoch: 2 [44800/143511 (31%)]\tLoss: 7.906240\n",
      "Train Epoch: 2 [46080/143511 (32%)]\tLoss: 6.079108\n",
      "Train Epoch: 2 [47360/143511 (33%)]\tLoss: 5.298965\n",
      "Train Epoch: 2 [48640/143511 (34%)]\tLoss: 5.528606\n",
      "Train Epoch: 2 [49920/143511 (35%)]\tLoss: 7.512505\n",
      "Train Epoch: 2 [51200/143511 (36%)]\tLoss: 8.541596\n",
      "Train Epoch: 2 [52480/143511 (37%)]\tLoss: 7.368730\n",
      "Train Epoch: 2 [53760/143511 (37%)]\tLoss: 6.187334\n",
      "Train Epoch: 2 [55040/143511 (38%)]\tLoss: 6.508243\n",
      "Train Epoch: 2 [56320/143511 (39%)]\tLoss: 5.760137\n",
      "Train Epoch: 2 [57600/143511 (40%)]\tLoss: 7.784523\n",
      "Train Epoch: 2 [58880/143511 (41%)]\tLoss: 6.207049\n",
      "Train Epoch: 2 [60160/143511 (42%)]\tLoss: 6.912253\n",
      "Train Epoch: 2 [61440/143511 (43%)]\tLoss: 7.791658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [62720/143511 (44%)]\tLoss: 5.029554\n",
      "Train Epoch: 2 [64000/143511 (45%)]\tLoss: 7.016000\n",
      "Train Epoch: 2 [65280/143511 (45%)]\tLoss: 5.635261\n",
      "Train Epoch: 2 [66560/143511 (46%)]\tLoss: 5.945562\n",
      "Train Epoch: 2 [67840/143511 (47%)]\tLoss: 4.993707\n",
      "Train Epoch: 2 [69120/143511 (48%)]\tLoss: 5.427718\n",
      "Train Epoch: 2 [70400/143511 (49%)]\tLoss: 5.219595\n",
      "Train Epoch: 2 [71680/143511 (50%)]\tLoss: 6.812445\n",
      "Train Epoch: 2 [72960/143511 (51%)]\tLoss: 4.978668\n",
      "Train Epoch: 2 [74240/143511 (52%)]\tLoss: 5.743450\n",
      "Train Epoch: 2 [75520/143511 (53%)]\tLoss: 7.197273\n",
      "Train Epoch: 2 [76800/143511 (53%)]\tLoss: 5.004735\n",
      "Train Epoch: 2 [78080/143511 (54%)]\tLoss: 6.842177\n",
      "Train Epoch: 2 [79360/143511 (55%)]\tLoss: 6.333487\n",
      "Train Epoch: 2 [80640/143511 (56%)]\tLoss: 5.433034\n",
      "Train Epoch: 2 [81920/143511 (57%)]\tLoss: 6.173864\n",
      "Train Epoch: 2 [83200/143511 (58%)]\tLoss: 7.439878\n",
      "Train Epoch: 2 [84480/143511 (59%)]\tLoss: 4.963384\n",
      "Train Epoch: 2 [85760/143511 (60%)]\tLoss: 6.219549\n",
      "Train Epoch: 2 [87040/143511 (61%)]\tLoss: 6.369997\n",
      "Train Epoch: 2 [88320/143511 (61%)]\tLoss: 5.949635\n",
      "Train Epoch: 2 [89600/143511 (62%)]\tLoss: 5.621800\n",
      "Train Epoch: 2 [90880/143511 (63%)]\tLoss: 7.055959\n",
      "Train Epoch: 2 [92160/143511 (64%)]\tLoss: 8.093607\n",
      "Train Epoch: 2 [93440/143511 (65%)]\tLoss: 7.142533\n",
      "Train Epoch: 2 [94720/143511 (66%)]\tLoss: 6.021617\n",
      "Train Epoch: 2 [96000/143511 (67%)]\tLoss: 5.699710\n",
      "Train Epoch: 2 [97280/143511 (68%)]\tLoss: 6.732382\n",
      "Train Epoch: 2 [98560/143511 (69%)]\tLoss: 5.583523\n",
      "Train Epoch: 2 [99840/143511 (70%)]\tLoss: 6.079742\n",
      "Train Epoch: 2 [101120/143511 (70%)]\tLoss: 6.226912\n",
      "Train Epoch: 2 [102400/143511 (71%)]\tLoss: 5.100545\n",
      "Train Epoch: 2 [103680/143511 (72%)]\tLoss: 5.442905\n",
      "Train Epoch: 2 [104960/143511 (73%)]\tLoss: 6.818797\n",
      "Train Epoch: 2 [106240/143511 (74%)]\tLoss: 7.095618\n",
      "Train Epoch: 2 [107520/143511 (75%)]\tLoss: 5.882311\n",
      "Train Epoch: 2 [108800/143511 (76%)]\tLoss: 6.091033\n",
      "Train Epoch: 2 [110080/143511 (77%)]\tLoss: 6.063648\n",
      "Train Epoch: 2 [111360/143511 (78%)]\tLoss: 7.100388\n",
      "Train Epoch: 2 [112640/143511 (78%)]\tLoss: 6.664784\n",
      "Train Epoch: 2 [113920/143511 (79%)]\tLoss: 7.037799\n",
      "Train Epoch: 2 [115200/143511 (80%)]\tLoss: 6.893181\n",
      "Train Epoch: 2 [116480/143511 (81%)]\tLoss: 6.898794\n",
      "Train Epoch: 2 [117760/143511 (82%)]\tLoss: 6.517502\n",
      "Train Epoch: 2 [119040/143511 (83%)]\tLoss: 7.182414\n",
      "Train Epoch: 2 [120320/143511 (84%)]\tLoss: 6.792953\n",
      "Train Epoch: 2 [121600/143511 (85%)]\tLoss: 6.711048\n",
      "Train Epoch: 2 [122880/143511 (86%)]\tLoss: 6.522025\n",
      "Train Epoch: 2 [124160/143511 (86%)]\tLoss: 6.521920\n",
      "Train Epoch: 2 [125440/143511 (87%)]\tLoss: 6.709277\n",
      "Train Epoch: 2 [126720/143511 (88%)]\tLoss: 7.655170\n",
      "Train Epoch: 2 [128000/143511 (89%)]\tLoss: 5.964021\n",
      "Train Epoch: 2 [129280/143511 (90%)]\tLoss: 5.396898\n",
      "Train Epoch: 2 [130560/143511 (91%)]\tLoss: 6.619099\n",
      "Train Epoch: 2 [131840/143511 (92%)]\tLoss: 5.136109\n",
      "Train Epoch: 2 [133120/143511 (93%)]\tLoss: 7.354339\n",
      "Train Epoch: 2 [134400/143511 (94%)]\tLoss: 5.981040\n",
      "Train Epoch: 2 [135680/143511 (94%)]\tLoss: 7.563553\n",
      "Train Epoch: 2 [136960/143511 (95%)]\tLoss: 5.667766\n",
      "Train Epoch: 2 [138240/143511 (96%)]\tLoss: 5.012242\n",
      "Train Epoch: 2 [139520/143511 (97%)]\tLoss: 5.780169\n",
      "Train Epoch: 2 [140800/143511 (98%)]\tLoss: 5.203033\n",
      "Train Epoch: 2 [142080/143511 (99%)]\tLoss: 5.721183\n",
      "Train Epoch: 2 [143360/143511 (100%)]\tLoss: 6.765058\n",
      "====> Epoch: 2 Average loss: 6.3411\n",
      "Train Epoch: 3 [0/143511 (0%)]\tLoss: 5.757843\n",
      "Train Epoch: 3 [1280/143511 (1%)]\tLoss: 5.271984\n",
      "Train Epoch: 3 [2560/143511 (2%)]\tLoss: 7.409598\n",
      "Train Epoch: 3 [3840/143511 (3%)]\tLoss: 5.718840\n",
      "Train Epoch: 3 [5120/143511 (4%)]\tLoss: 5.854867\n",
      "Train Epoch: 3 [6400/143511 (4%)]\tLoss: 6.035534\n",
      "Train Epoch: 3 [7680/143511 (5%)]\tLoss: 6.763371\n",
      "Train Epoch: 3 [8960/143511 (6%)]\tLoss: 7.245391\n",
      "Train Epoch: 3 [10240/143511 (7%)]\tLoss: 5.900936\n",
      "Train Epoch: 3 [11520/143511 (8%)]\tLoss: 5.699519\n",
      "Train Epoch: 3 [12800/143511 (9%)]\tLoss: 6.806324\n",
      "Train Epoch: 3 [14080/143511 (10%)]\tLoss: 7.627941\n",
      "Train Epoch: 3 [15360/143511 (11%)]\tLoss: 6.385766\n",
      "Train Epoch: 3 [16640/143511 (12%)]\tLoss: 5.638761\n",
      "Train Epoch: 3 [17920/143511 (12%)]\tLoss: 6.196079\n",
      "Train Epoch: 3 [19200/143511 (13%)]\tLoss: 6.915211\n",
      "Train Epoch: 3 [20480/143511 (14%)]\tLoss: 5.600268\n",
      "Train Epoch: 3 [21760/143511 (15%)]\tLoss: 5.498153\n",
      "Train Epoch: 3 [23040/143511 (16%)]\tLoss: 6.407401\n",
      "Train Epoch: 3 [24320/143511 (17%)]\tLoss: 6.872743\n",
      "Train Epoch: 3 [25600/143511 (18%)]\tLoss: 7.011001\n",
      "Train Epoch: 3 [26880/143511 (19%)]\tLoss: 5.472097\n",
      "Train Epoch: 3 [28160/143511 (20%)]\tLoss: 5.425573\n",
      "Train Epoch: 3 [29440/143511 (20%)]\tLoss: 6.713801\n",
      "Train Epoch: 3 [30720/143511 (21%)]\tLoss: 7.351747\n",
      "Train Epoch: 3 [32000/143511 (22%)]\tLoss: 6.377584\n",
      "Train Epoch: 3 [33280/143511 (23%)]\tLoss: 5.700617\n",
      "Train Epoch: 3 [34560/143511 (24%)]\tLoss: 4.947475\n",
      "Train Epoch: 3 [35840/143511 (25%)]\tLoss: 5.494678\n",
      "Train Epoch: 3 [37120/143511 (26%)]\tLoss: 6.720976\n",
      "Train Epoch: 3 [38400/143511 (27%)]\tLoss: 5.095973\n",
      "Train Epoch: 3 [39680/143511 (28%)]\tLoss: 5.862864\n",
      "Train Epoch: 3 [40960/143511 (29%)]\tLoss: 6.477668\n",
      "Train Epoch: 3 [42240/143511 (29%)]\tLoss: 6.717117\n",
      "Train Epoch: 3 [43520/143511 (30%)]\tLoss: 6.647388\n",
      "Train Epoch: 3 [44800/143511 (31%)]\tLoss: 6.441380\n",
      "Train Epoch: 3 [46080/143511 (32%)]\tLoss: 5.800563\n",
      "Train Epoch: 3 [47360/143511 (33%)]\tLoss: 5.217857\n",
      "Train Epoch: 3 [48640/143511 (34%)]\tLoss: 5.338902\n",
      "Train Epoch: 3 [49920/143511 (35%)]\tLoss: 6.475846\n",
      "Train Epoch: 3 [51200/143511 (36%)]\tLoss: 5.258780\n",
      "Train Epoch: 3 [52480/143511 (37%)]\tLoss: 6.531201\n",
      "Train Epoch: 3 [53760/143511 (37%)]\tLoss: 7.197744\n",
      "Train Epoch: 3 [55040/143511 (38%)]\tLoss: 6.243869\n",
      "Train Epoch: 3 [56320/143511 (39%)]\tLoss: 6.681682\n",
      "Train Epoch: 3 [57600/143511 (40%)]\tLoss: 6.210097\n",
      "Train Epoch: 3 [58880/143511 (41%)]\tLoss: 7.467161\n",
      "Train Epoch: 3 [60160/143511 (42%)]\tLoss: 5.935875\n",
      "Train Epoch: 3 [61440/143511 (43%)]\tLoss: 5.885623\n",
      "Train Epoch: 3 [62720/143511 (44%)]\tLoss: 5.537750\n",
      "Train Epoch: 3 [64000/143511 (45%)]\tLoss: 5.839159\n",
      "Train Epoch: 3 [65280/143511 (45%)]\tLoss: 6.320764\n",
      "Train Epoch: 3 [66560/143511 (46%)]\tLoss: 6.412417\n",
      "Train Epoch: 3 [67840/143511 (47%)]\tLoss: 5.333434\n",
      "Train Epoch: 3 [69120/143511 (48%)]\tLoss: 5.810228\n",
      "Train Epoch: 3 [70400/143511 (49%)]\tLoss: 6.313637\n",
      "Train Epoch: 3 [71680/143511 (50%)]\tLoss: 7.319101\n",
      "Train Epoch: 3 [72960/143511 (51%)]\tLoss: 4.949715\n",
      "Train Epoch: 3 [74240/143511 (52%)]\tLoss: 6.864147\n",
      "Train Epoch: 3 [75520/143511 (53%)]\tLoss: 5.184393\n",
      "Train Epoch: 3 [76800/143511 (53%)]\tLoss: 6.105206\n",
      "Train Epoch: 3 [78080/143511 (54%)]\tLoss: 7.064885\n",
      "Train Epoch: 3 [79360/143511 (55%)]\tLoss: 5.992970\n",
      "Train Epoch: 3 [80640/143511 (56%)]\tLoss: 6.276081\n",
      "Train Epoch: 3 [81920/143511 (57%)]\tLoss: 6.411985\n",
      "Train Epoch: 3 [83200/143511 (58%)]\tLoss: 5.905114\n",
      "Train Epoch: 3 [84480/143511 (59%)]\tLoss: 7.429493\n",
      "Train Epoch: 3 [85760/143511 (60%)]\tLoss: 6.196504\n",
      "Train Epoch: 3 [87040/143511 (61%)]\tLoss: 6.094797\n",
      "Train Epoch: 3 [88320/143511 (61%)]\tLoss: 7.521589\n",
      "Train Epoch: 3 [89600/143511 (62%)]\tLoss: 6.383911\n",
      "Train Epoch: 3 [90880/143511 (63%)]\tLoss: 5.520366\n",
      "Train Epoch: 3 [92160/143511 (64%)]\tLoss: 7.867142\n",
      "Train Epoch: 3 [93440/143511 (65%)]\tLoss: 7.415504\n",
      "Train Epoch: 3 [94720/143511 (66%)]\tLoss: 7.022939\n",
      "Train Epoch: 3 [96000/143511 (67%)]\tLoss: 6.409275\n",
      "Train Epoch: 3 [97280/143511 (68%)]\tLoss: 6.389231\n",
      "Train Epoch: 3 [98560/143511 (69%)]\tLoss: 6.833109\n",
      "Train Epoch: 3 [99840/143511 (70%)]\tLoss: 7.015646\n",
      "Train Epoch: 3 [101120/143511 (70%)]\tLoss: 5.994789\n",
      "Train Epoch: 3 [102400/143511 (71%)]\tLoss: 5.417615\n",
      "Train Epoch: 3 [103680/143511 (72%)]\tLoss: 6.273918\n",
      "Train Epoch: 3 [104960/143511 (73%)]\tLoss: 6.195816\n",
      "Train Epoch: 3 [106240/143511 (74%)]\tLoss: 6.509454\n",
      "Train Epoch: 3 [107520/143511 (75%)]\tLoss: 5.761230\n",
      "Train Epoch: 3 [108800/143511 (76%)]\tLoss: 6.617600\n",
      "Train Epoch: 3 [110080/143511 (77%)]\tLoss: 7.286093\n",
      "Train Epoch: 3 [111360/143511 (78%)]\tLoss: 7.519208\n",
      "Train Epoch: 3 [112640/143511 (78%)]\tLoss: 7.689580\n",
      "Train Epoch: 3 [113920/143511 (79%)]\tLoss: 5.898826\n",
      "Train Epoch: 3 [115200/143511 (80%)]\tLoss: 5.551343\n",
      "Train Epoch: 3 [116480/143511 (81%)]\tLoss: 5.848751\n",
      "Train Epoch: 3 [117760/143511 (82%)]\tLoss: 7.045106\n",
      "Train Epoch: 3 [119040/143511 (83%)]\tLoss: 6.963110\n",
      "Train Epoch: 3 [120320/143511 (84%)]\tLoss: 5.789544\n",
      "Train Epoch: 3 [121600/143511 (85%)]\tLoss: 6.761481\n",
      "Train Epoch: 3 [122880/143511 (86%)]\tLoss: 5.742770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [124160/143511 (86%)]\tLoss: 5.133265\n",
      "Train Epoch: 3 [125440/143511 (87%)]\tLoss: 4.609357\n",
      "Train Epoch: 3 [126720/143511 (88%)]\tLoss: 6.624432\n",
      "Train Epoch: 3 [128000/143511 (89%)]\tLoss: 5.876292\n",
      "Train Epoch: 3 [129280/143511 (90%)]\tLoss: 6.722567\n",
      "Train Epoch: 3 [130560/143511 (91%)]\tLoss: 5.423199\n",
      "Train Epoch: 3 [131840/143511 (92%)]\tLoss: 6.385238\n",
      "Train Epoch: 3 [133120/143511 (93%)]\tLoss: 7.321950\n",
      "Train Epoch: 3 [134400/143511 (94%)]\tLoss: 6.019308\n",
      "Train Epoch: 3 [135680/143511 (94%)]\tLoss: 5.963578\n",
      "Train Epoch: 3 [136960/143511 (95%)]\tLoss: 6.700415\n",
      "Train Epoch: 3 [138240/143511 (96%)]\tLoss: 5.906267\n",
      "Train Epoch: 3 [139520/143511 (97%)]\tLoss: 6.367434\n",
      "Train Epoch: 3 [140800/143511 (98%)]\tLoss: 5.205314\n",
      "Train Epoch: 3 [142080/143511 (99%)]\tLoss: 5.074015\n",
      "Train Epoch: 3 [143360/143511 (100%)]\tLoss: 6.063494\n",
      "====> Epoch: 3 Average loss: 6.2945\n",
      "Train Epoch: 4 [0/143511 (0%)]\tLoss: 6.901792\n",
      "Train Epoch: 4 [1280/143511 (1%)]\tLoss: 7.673475\n",
      "Train Epoch: 4 [2560/143511 (2%)]\tLoss: 6.296178\n",
      "Train Epoch: 4 [3840/143511 (3%)]\tLoss: 6.410991\n",
      "Train Epoch: 4 [5120/143511 (4%)]\tLoss: 6.678083\n",
      "Train Epoch: 4 [6400/143511 (4%)]\tLoss: 5.597352\n",
      "Train Epoch: 4 [7680/143511 (5%)]\tLoss: 6.019117\n",
      "Train Epoch: 4 [8960/143511 (6%)]\tLoss: 6.031782\n",
      "Train Epoch: 4 [10240/143511 (7%)]\tLoss: 8.207157\n",
      "Train Epoch: 4 [11520/143511 (8%)]\tLoss: 5.410543\n",
      "Train Epoch: 4 [12800/143511 (9%)]\tLoss: 7.061026\n",
      "Train Epoch: 4 [14080/143511 (10%)]\tLoss: 6.451674\n",
      "Train Epoch: 4 [15360/143511 (11%)]\tLoss: 5.902339\n",
      "Train Epoch: 4 [16640/143511 (12%)]\tLoss: 5.757475\n",
      "Train Epoch: 4 [17920/143511 (12%)]\tLoss: 6.072431\n",
      "Train Epoch: 4 [19200/143511 (13%)]\tLoss: 5.795658\n",
      "Train Epoch: 4 [20480/143511 (14%)]\tLoss: 6.676167\n",
      "Train Epoch: 4 [21760/143511 (15%)]\tLoss: 6.578544\n",
      "Train Epoch: 4 [23040/143511 (16%)]\tLoss: 5.816858\n",
      "Train Epoch: 4 [24320/143511 (17%)]\tLoss: 6.088160\n",
      "Train Epoch: 4 [25600/143511 (18%)]\tLoss: 5.388714\n",
      "Train Epoch: 4 [26880/143511 (19%)]\tLoss: 6.492632\n",
      "Train Epoch: 4 [28160/143511 (20%)]\tLoss: 5.690495\n",
      "Train Epoch: 4 [29440/143511 (20%)]\tLoss: 6.002779\n",
      "Train Epoch: 4 [30720/143511 (21%)]\tLoss: 6.363559\n",
      "Train Epoch: 4 [32000/143511 (22%)]\tLoss: 6.351958\n",
      "Train Epoch: 4 [33280/143511 (23%)]\tLoss: 7.160958\n",
      "Train Epoch: 4 [34560/143511 (24%)]\tLoss: 5.709144\n",
      "Train Epoch: 4 [35840/143511 (25%)]\tLoss: 6.228748\n",
      "Train Epoch: 4 [37120/143511 (26%)]\tLoss: 5.578969\n",
      "Train Epoch: 4 [38400/143511 (27%)]\tLoss: 6.057157\n",
      "Train Epoch: 4 [39680/143511 (28%)]\tLoss: 4.969863\n",
      "Train Epoch: 4 [40960/143511 (29%)]\tLoss: 6.513460\n",
      "Train Epoch: 4 [42240/143511 (29%)]\tLoss: 5.670457\n",
      "Train Epoch: 4 [43520/143511 (30%)]\tLoss: 5.019835\n",
      "Train Epoch: 4 [44800/143511 (31%)]\tLoss: 7.144308\n",
      "Train Epoch: 4 [46080/143511 (32%)]\tLoss: 6.192428\n",
      "Train Epoch: 4 [47360/143511 (33%)]\tLoss: 6.472312\n",
      "Train Epoch: 4 [48640/143511 (34%)]\tLoss: 5.169459\n",
      "Train Epoch: 4 [49920/143511 (35%)]\tLoss: 5.850346\n",
      "Train Epoch: 4 [51200/143511 (36%)]\tLoss: 6.267597\n",
      "Train Epoch: 4 [52480/143511 (37%)]\tLoss: 6.031676\n",
      "Train Epoch: 4 [53760/143511 (37%)]\tLoss: 6.050385\n",
      "Train Epoch: 4 [55040/143511 (38%)]\tLoss: 6.171813\n",
      "Train Epoch: 4 [56320/143511 (39%)]\tLoss: 5.769434\n",
      "Train Epoch: 4 [57600/143511 (40%)]\tLoss: 7.476765\n",
      "Train Epoch: 4 [58880/143511 (41%)]\tLoss: 6.946249\n",
      "Train Epoch: 4 [60160/143511 (42%)]\tLoss: 5.465861\n",
      "Train Epoch: 4 [61440/143511 (43%)]\tLoss: 4.932722\n",
      "Train Epoch: 4 [62720/143511 (44%)]\tLoss: 6.516143\n",
      "Train Epoch: 4 [64000/143511 (45%)]\tLoss: 7.393970\n",
      "Train Epoch: 4 [65280/143511 (45%)]\tLoss: 6.233142\n",
      "Train Epoch: 4 [66560/143511 (46%)]\tLoss: 5.935285\n",
      "Train Epoch: 4 [67840/143511 (47%)]\tLoss: 6.648367\n",
      "Train Epoch: 4 [69120/143511 (48%)]\tLoss: 6.214059\n",
      "Train Epoch: 4 [70400/143511 (49%)]\tLoss: 5.491959\n",
      "Train Epoch: 4 [71680/143511 (50%)]\tLoss: 5.542831\n",
      "Train Epoch: 4 [72960/143511 (51%)]\tLoss: 5.748460\n",
      "Train Epoch: 4 [74240/143511 (52%)]\tLoss: 5.348089\n",
      "Train Epoch: 4 [75520/143511 (53%)]\tLoss: 5.054168\n",
      "Train Epoch: 4 [76800/143511 (53%)]\tLoss: 6.501154\n",
      "Train Epoch: 4 [78080/143511 (54%)]\tLoss: 5.796818\n",
      "Train Epoch: 4 [79360/143511 (55%)]\tLoss: 5.602436\n",
      "Train Epoch: 4 [80640/143511 (56%)]\tLoss: 5.835208\n",
      "Train Epoch: 4 [81920/143511 (57%)]\tLoss: 5.401975\n",
      "Train Epoch: 4 [83200/143511 (58%)]\tLoss: 5.635484\n",
      "Train Epoch: 4 [84480/143511 (59%)]\tLoss: 5.390637\n",
      "Train Epoch: 4 [85760/143511 (60%)]\tLoss: 6.698648\n",
      "Train Epoch: 4 [87040/143511 (61%)]\tLoss: 6.070680\n",
      "Train Epoch: 4 [88320/143511 (61%)]\tLoss: 7.454814\n",
      "Train Epoch: 4 [89600/143511 (62%)]\tLoss: 6.397856\n",
      "Train Epoch: 4 [90880/143511 (63%)]\tLoss: 5.533160\n",
      "Train Epoch: 4 [92160/143511 (64%)]\tLoss: 5.723443\n",
      "Train Epoch: 4 [93440/143511 (65%)]\tLoss: 5.323408\n",
      "Train Epoch: 4 [94720/143511 (66%)]\tLoss: 6.287070\n",
      "Train Epoch: 4 [96000/143511 (67%)]\tLoss: 5.015532\n",
      "Train Epoch: 4 [97280/143511 (68%)]\tLoss: 6.086112\n",
      "Train Epoch: 4 [98560/143511 (69%)]\tLoss: 5.957718\n",
      "Train Epoch: 4 [99840/143511 (70%)]\tLoss: 5.748782\n",
      "Train Epoch: 4 [101120/143511 (70%)]\tLoss: 5.530982\n",
      "Train Epoch: 4 [102400/143511 (71%)]\tLoss: 6.362238\n",
      "Train Epoch: 4 [103680/143511 (72%)]\tLoss: 5.346045\n",
      "Train Epoch: 4 [104960/143511 (73%)]\tLoss: 6.184154\n",
      "Train Epoch: 4 [106240/143511 (74%)]\tLoss: 8.124421\n",
      "Train Epoch: 4 [107520/143511 (75%)]\tLoss: 7.191447\n",
      "Train Epoch: 4 [108800/143511 (76%)]\tLoss: 6.695188\n",
      "Train Epoch: 4 [110080/143511 (77%)]\tLoss: 5.596167\n",
      "Train Epoch: 4 [111360/143511 (78%)]\tLoss: 5.823584\n",
      "Train Epoch: 4 [112640/143511 (78%)]\tLoss: 6.769057\n",
      "Train Epoch: 4 [113920/143511 (79%)]\tLoss: 5.220483\n",
      "Train Epoch: 4 [115200/143511 (80%)]\tLoss: 5.368608\n",
      "Train Epoch: 4 [116480/143511 (81%)]\tLoss: 5.238463\n",
      "Train Epoch: 4 [117760/143511 (82%)]\tLoss: 5.748938\n",
      "Train Epoch: 4 [119040/143511 (83%)]\tLoss: 6.423657\n",
      "Train Epoch: 4 [120320/143511 (84%)]\tLoss: 7.280888\n",
      "Train Epoch: 4 [121600/143511 (85%)]\tLoss: 7.853404\n",
      "Train Epoch: 4 [122880/143511 (86%)]\tLoss: 6.061564\n",
      "Train Epoch: 4 [124160/143511 (86%)]\tLoss: 5.339318\n",
      "Train Epoch: 4 [125440/143511 (87%)]\tLoss: 6.300863\n",
      "Train Epoch: 4 [126720/143511 (88%)]\tLoss: 5.627198\n",
      "Train Epoch: 4 [128000/143511 (89%)]\tLoss: 6.006431\n",
      "Train Epoch: 4 [129280/143511 (90%)]\tLoss: 6.646137\n",
      "Train Epoch: 4 [130560/143511 (91%)]\tLoss: 5.913097\n",
      "Train Epoch: 4 [131840/143511 (92%)]\tLoss: 6.334018\n",
      "Train Epoch: 4 [133120/143511 (93%)]\tLoss: 5.401027\n",
      "Train Epoch: 4 [134400/143511 (94%)]\tLoss: 5.559581\n",
      "Train Epoch: 4 [135680/143511 (94%)]\tLoss: 5.743247\n",
      "Train Epoch: 4 [136960/143511 (95%)]\tLoss: 6.588780\n",
      "Train Epoch: 4 [138240/143511 (96%)]\tLoss: 7.361761\n",
      "Train Epoch: 4 [139520/143511 (97%)]\tLoss: 5.059663\n",
      "Train Epoch: 4 [140800/143511 (98%)]\tLoss: 6.106123\n",
      "Train Epoch: 4 [142080/143511 (99%)]\tLoss: 6.368002\n",
      "Train Epoch: 4 [143360/143511 (100%)]\tLoss: 7.592653\n",
      "====> Epoch: 4 Average loss: 6.2417\n",
      "Train Epoch: 5 [0/143511 (0%)]\tLoss: 5.128976\n",
      "Train Epoch: 5 [1280/143511 (1%)]\tLoss: 6.072869\n",
      "Train Epoch: 5 [2560/143511 (2%)]\tLoss: 6.596018\n",
      "Train Epoch: 5 [3840/143511 (3%)]\tLoss: 6.653422\n",
      "Train Epoch: 5 [5120/143511 (4%)]\tLoss: 5.489614\n",
      "Train Epoch: 5 [6400/143511 (4%)]\tLoss: 5.372025\n",
      "Train Epoch: 5 [7680/143511 (5%)]\tLoss: 6.908093\n",
      "Train Epoch: 5 [8960/143511 (6%)]\tLoss: 6.060542\n",
      "Train Epoch: 5 [10240/143511 (7%)]\tLoss: 6.782788\n",
      "Train Epoch: 5 [11520/143511 (8%)]\tLoss: 7.104291\n",
      "Train Epoch: 5 [12800/143511 (9%)]\tLoss: 6.126949\n",
      "Train Epoch: 5 [14080/143511 (10%)]\tLoss: 5.461662\n",
      "Train Epoch: 5 [15360/143511 (11%)]\tLoss: 6.460630\n",
      "Train Epoch: 5 [16640/143511 (12%)]\tLoss: 5.427800\n",
      "Train Epoch: 5 [17920/143511 (12%)]\tLoss: 4.575987\n",
      "Train Epoch: 5 [19200/143511 (13%)]\tLoss: 5.208846\n",
      "Train Epoch: 5 [20480/143511 (14%)]\tLoss: 7.724357\n",
      "Train Epoch: 5 [21760/143511 (15%)]\tLoss: 5.613610\n",
      "Train Epoch: 5 [23040/143511 (16%)]\tLoss: 7.286932\n",
      "Train Epoch: 5 [24320/143511 (17%)]\tLoss: 6.353727\n",
      "Train Epoch: 5 [25600/143511 (18%)]\tLoss: 6.493966\n",
      "Train Epoch: 5 [26880/143511 (19%)]\tLoss: 6.511311\n",
      "Train Epoch: 5 [28160/143511 (20%)]\tLoss: 6.447169\n",
      "Train Epoch: 5 [29440/143511 (20%)]\tLoss: 5.433330\n",
      "Train Epoch: 5 [30720/143511 (21%)]\tLoss: 5.814144\n",
      "Train Epoch: 5 [32000/143511 (22%)]\tLoss: 4.825950\n",
      "Train Epoch: 5 [33280/143511 (23%)]\tLoss: 6.502743\n",
      "Train Epoch: 5 [34560/143511 (24%)]\tLoss: 5.151999\n",
      "Train Epoch: 5 [35840/143511 (25%)]\tLoss: 6.867771\n",
      "Train Epoch: 5 [37120/143511 (26%)]\tLoss: 6.419590\n",
      "Train Epoch: 5 [38400/143511 (27%)]\tLoss: 5.389516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [39680/143511 (28%)]\tLoss: 6.081035\n",
      "Train Epoch: 5 [40960/143511 (29%)]\tLoss: 6.316836\n",
      "Train Epoch: 5 [42240/143511 (29%)]\tLoss: 7.112247\n",
      "Train Epoch: 5 [43520/143511 (30%)]\tLoss: 6.007400\n",
      "Train Epoch: 5 [44800/143511 (31%)]\tLoss: 6.146648\n",
      "Train Epoch: 5 [46080/143511 (32%)]\tLoss: 6.690079\n",
      "Train Epoch: 5 [47360/143511 (33%)]\tLoss: 6.551326\n",
      "Train Epoch: 5 [48640/143511 (34%)]\tLoss: 7.014645\n",
      "Train Epoch: 5 [49920/143511 (35%)]\tLoss: 5.802001\n",
      "Train Epoch: 5 [51200/143511 (36%)]\tLoss: 6.383507\n",
      "Train Epoch: 5 [52480/143511 (37%)]\tLoss: 5.114145\n",
      "Train Epoch: 5 [53760/143511 (37%)]\tLoss: 5.207792\n",
      "Train Epoch: 5 [55040/143511 (38%)]\tLoss: 6.650043\n",
      "Train Epoch: 5 [56320/143511 (39%)]\tLoss: 6.741393\n",
      "Train Epoch: 5 [57600/143511 (40%)]\tLoss: 4.983960\n",
      "Train Epoch: 5 [58880/143511 (41%)]\tLoss: 6.413943\n",
      "Train Epoch: 5 [60160/143511 (42%)]\tLoss: 6.316024\n",
      "Train Epoch: 5 [61440/143511 (43%)]\tLoss: 6.129595\n",
      "Train Epoch: 5 [62720/143511 (44%)]\tLoss: 6.530789\n",
      "Train Epoch: 5 [64000/143511 (45%)]\tLoss: 7.380051\n",
      "Train Epoch: 5 [65280/143511 (45%)]\tLoss: 6.986572\n",
      "Train Epoch: 5 [66560/143511 (46%)]\tLoss: 6.893218\n",
      "Train Epoch: 5 [67840/143511 (47%)]\tLoss: 6.318048\n",
      "Train Epoch: 5 [69120/143511 (48%)]\tLoss: 5.511364\n",
      "Train Epoch: 5 [70400/143511 (49%)]\tLoss: 5.897225\n",
      "Train Epoch: 5 [71680/143511 (50%)]\tLoss: 4.807397\n",
      "Train Epoch: 5 [72960/143511 (51%)]\tLoss: 7.260576\n",
      "Train Epoch: 5 [74240/143511 (52%)]\tLoss: 7.136468\n",
      "Train Epoch: 5 [75520/143511 (53%)]\tLoss: 6.340573\n",
      "Train Epoch: 5 [76800/143511 (53%)]\tLoss: 5.956064\n",
      "Train Epoch: 5 [78080/143511 (54%)]\tLoss: 6.241118\n",
      "Train Epoch: 5 [79360/143511 (55%)]\tLoss: 6.728939\n",
      "Train Epoch: 5 [80640/143511 (56%)]\tLoss: 5.819601\n",
      "Train Epoch: 5 [81920/143511 (57%)]\tLoss: 5.759290\n",
      "Train Epoch: 5 [83200/143511 (58%)]\tLoss: 5.995120\n",
      "Train Epoch: 5 [84480/143511 (59%)]\tLoss: 6.524813\n",
      "Train Epoch: 5 [85760/143511 (60%)]\tLoss: 6.659052\n",
      "Train Epoch: 5 [87040/143511 (61%)]\tLoss: 5.528948\n",
      "Train Epoch: 5 [88320/143511 (61%)]\tLoss: 6.173120\n",
      "Train Epoch: 5 [89600/143511 (62%)]\tLoss: 5.978158\n",
      "Train Epoch: 5 [90880/143511 (63%)]\tLoss: 6.377796\n",
      "Train Epoch: 5 [92160/143511 (64%)]\tLoss: 7.517406\n",
      "Train Epoch: 5 [93440/143511 (65%)]\tLoss: 5.814742\n",
      "Train Epoch: 5 [94720/143511 (66%)]\tLoss: 7.243136\n",
      "Train Epoch: 5 [96000/143511 (67%)]\tLoss: 5.277956\n",
      "Train Epoch: 5 [97280/143511 (68%)]\tLoss: 6.500238\n",
      "Train Epoch: 5 [98560/143511 (69%)]\tLoss: 5.770765\n",
      "Train Epoch: 5 [99840/143511 (70%)]\tLoss: 5.818904\n",
      "Train Epoch: 5 [101120/143511 (70%)]\tLoss: 5.525182\n",
      "Train Epoch: 5 [102400/143511 (71%)]\tLoss: 5.340951\n",
      "Train Epoch: 5 [103680/143511 (72%)]\tLoss: 7.739715\n",
      "Train Epoch: 5 [104960/143511 (73%)]\tLoss: 5.647037\n",
      "Train Epoch: 5 [106240/143511 (74%)]\tLoss: 6.175851\n",
      "Train Epoch: 5 [107520/143511 (75%)]\tLoss: 5.565894\n",
      "Train Epoch: 5 [108800/143511 (76%)]\tLoss: 5.700307\n",
      "Train Epoch: 5 [110080/143511 (77%)]\tLoss: 6.563260\n",
      "Train Epoch: 5 [111360/143511 (78%)]\tLoss: 6.326326\n",
      "Train Epoch: 5 [112640/143511 (78%)]\tLoss: 8.047737\n",
      "Train Epoch: 5 [113920/143511 (79%)]\tLoss: 5.972034\n",
      "Train Epoch: 5 [115200/143511 (80%)]\tLoss: 6.517136\n",
      "Train Epoch: 5 [116480/143511 (81%)]\tLoss: 7.391205\n",
      "Train Epoch: 5 [117760/143511 (82%)]\tLoss: 6.914329\n",
      "Train Epoch: 5 [119040/143511 (83%)]\tLoss: 6.536773\n",
      "Train Epoch: 5 [120320/143511 (84%)]\tLoss: 6.461746\n",
      "Train Epoch: 5 [121600/143511 (85%)]\tLoss: 5.203715\n",
      "Train Epoch: 5 [122880/143511 (86%)]\tLoss: 5.119615\n",
      "Train Epoch: 5 [124160/143511 (86%)]\tLoss: 6.187905\n",
      "Train Epoch: 5 [125440/143511 (87%)]\tLoss: 6.393561\n",
      "Train Epoch: 5 [126720/143511 (88%)]\tLoss: 5.646005\n",
      "Train Epoch: 5 [128000/143511 (89%)]\tLoss: 7.176007\n",
      "Train Epoch: 5 [129280/143511 (90%)]\tLoss: 5.440059\n",
      "Train Epoch: 5 [130560/143511 (91%)]\tLoss: 7.871744\n",
      "Train Epoch: 5 [131840/143511 (92%)]\tLoss: 7.303573\n",
      "Train Epoch: 5 [133120/143511 (93%)]\tLoss: 6.616107\n",
      "Train Epoch: 5 [134400/143511 (94%)]\tLoss: 6.811348\n",
      "Train Epoch: 5 [135680/143511 (94%)]\tLoss: 6.674470\n",
      "Train Epoch: 5 [136960/143511 (95%)]\tLoss: 6.188083\n",
      "Train Epoch: 5 [138240/143511 (96%)]\tLoss: 6.427874\n",
      "Train Epoch: 5 [139520/143511 (97%)]\tLoss: 7.444648\n",
      "Train Epoch: 5 [140800/143511 (98%)]\tLoss: 6.148407\n",
      "Train Epoch: 5 [142080/143511 (99%)]\tLoss: 5.371795\n",
      "Train Epoch: 5 [143360/143511 (100%)]\tLoss: 5.990498\n",
      "====> Epoch: 5 Average loss: 6.2047\n",
      "Train Epoch: 6 [0/143511 (0%)]\tLoss: 5.415049\n",
      "Train Epoch: 6 [1280/143511 (1%)]\tLoss: 7.095895\n",
      "Train Epoch: 6 [2560/143511 (2%)]\tLoss: 7.066641\n",
      "Train Epoch: 6 [3840/143511 (3%)]\tLoss: 7.367352\n",
      "Train Epoch: 6 [5120/143511 (4%)]\tLoss: 6.752832\n",
      "Train Epoch: 6 [6400/143511 (4%)]\tLoss: 5.863564\n",
      "Train Epoch: 6 [7680/143511 (5%)]\tLoss: 6.791062\n",
      "Train Epoch: 6 [8960/143511 (6%)]\tLoss: 5.838783\n",
      "Train Epoch: 6 [10240/143511 (7%)]\tLoss: 6.176644\n",
      "Train Epoch: 6 [11520/143511 (8%)]\tLoss: 5.720219\n",
      "Train Epoch: 6 [12800/143511 (9%)]\tLoss: 5.280723\n",
      "Train Epoch: 6 [14080/143511 (10%)]\tLoss: 6.637918\n",
      "Train Epoch: 6 [15360/143511 (11%)]\tLoss: 6.039147\n",
      "Train Epoch: 6 [16640/143511 (12%)]\tLoss: 6.661873\n",
      "Train Epoch: 6 [17920/143511 (12%)]\tLoss: 7.225110\n",
      "Train Epoch: 6 [19200/143511 (13%)]\tLoss: 7.551033\n",
      "Train Epoch: 6 [20480/143511 (14%)]\tLoss: 5.963761\n",
      "Train Epoch: 6 [21760/143511 (15%)]\tLoss: 7.063061\n",
      "Train Epoch: 6 [23040/143511 (16%)]\tLoss: 5.744572\n",
      "Train Epoch: 6 [24320/143511 (17%)]\tLoss: 5.953249\n",
      "Train Epoch: 6 [25600/143511 (18%)]\tLoss: 5.263494\n",
      "Train Epoch: 6 [26880/143511 (19%)]\tLoss: 5.854796\n",
      "Train Epoch: 6 [28160/143511 (20%)]\tLoss: 6.535447\n",
      "Train Epoch: 6 [29440/143511 (20%)]\tLoss: 5.829186\n",
      "Train Epoch: 6 [30720/143511 (21%)]\tLoss: 6.130181\n",
      "Train Epoch: 6 [32000/143511 (22%)]\tLoss: 6.210419\n",
      "Train Epoch: 6 [33280/143511 (23%)]\tLoss: 6.107031\n",
      "Train Epoch: 6 [34560/143511 (24%)]\tLoss: 6.783631\n",
      "Train Epoch: 6 [35840/143511 (25%)]\tLoss: 6.299623\n",
      "Train Epoch: 6 [37120/143511 (26%)]\tLoss: 5.965393\n",
      "Train Epoch: 6 [38400/143511 (27%)]\tLoss: 6.182483\n",
      "Train Epoch: 6 [39680/143511 (28%)]\tLoss: 6.844172\n",
      "Train Epoch: 6 [40960/143511 (29%)]\tLoss: 6.268127\n",
      "Train Epoch: 6 [42240/143511 (29%)]\tLoss: 5.166159\n",
      "Train Epoch: 6 [43520/143511 (30%)]\tLoss: 5.494524\n",
      "Train Epoch: 6 [44800/143511 (31%)]\tLoss: 5.775216\n",
      "Train Epoch: 6 [46080/143511 (32%)]\tLoss: 5.836020\n",
      "Train Epoch: 6 [47360/143511 (33%)]\tLoss: 5.997409\n",
      "Train Epoch: 6 [48640/143511 (34%)]\tLoss: 5.207622\n",
      "Train Epoch: 6 [49920/143511 (35%)]\tLoss: 5.324097\n",
      "Train Epoch: 6 [51200/143511 (36%)]\tLoss: 5.899687\n",
      "Train Epoch: 6 [52480/143511 (37%)]\tLoss: 5.952574\n",
      "Train Epoch: 6 [53760/143511 (37%)]\tLoss: 5.915570\n",
      "Train Epoch: 6 [55040/143511 (38%)]\tLoss: 6.810416\n",
      "Train Epoch: 6 [56320/143511 (39%)]\tLoss: 4.655484\n",
      "Train Epoch: 6 [57600/143511 (40%)]\tLoss: 5.770553\n",
      "Train Epoch: 6 [58880/143511 (41%)]\tLoss: 5.491303\n",
      "Train Epoch: 6 [60160/143511 (42%)]\tLoss: 6.171082\n",
      "Train Epoch: 6 [61440/143511 (43%)]\tLoss: 6.376902\n",
      "Train Epoch: 6 [62720/143511 (44%)]\tLoss: 6.438212\n",
      "Train Epoch: 6 [64000/143511 (45%)]\tLoss: 6.976896\n",
      "Train Epoch: 6 [65280/143511 (45%)]\tLoss: 6.120321\n",
      "Train Epoch: 6 [66560/143511 (46%)]\tLoss: 7.071763\n",
      "Train Epoch: 6 [67840/143511 (47%)]\tLoss: 5.683487\n",
      "Train Epoch: 6 [69120/143511 (48%)]\tLoss: 6.482632\n",
      "Train Epoch: 6 [70400/143511 (49%)]\tLoss: 5.807163\n",
      "Train Epoch: 6 [71680/143511 (50%)]\tLoss: 6.458949\n",
      "Train Epoch: 6 [72960/143511 (51%)]\tLoss: 7.067876\n",
      "Train Epoch: 6 [74240/143511 (52%)]\tLoss: 6.062953\n",
      "Train Epoch: 6 [75520/143511 (53%)]\tLoss: 6.914624\n",
      "Train Epoch: 6 [76800/143511 (53%)]\tLoss: 6.086387\n",
      "Train Epoch: 6 [78080/143511 (54%)]\tLoss: 6.499680\n",
      "Train Epoch: 6 [79360/143511 (55%)]\tLoss: 7.838843\n",
      "Train Epoch: 6 [80640/143511 (56%)]\tLoss: 7.364901\n",
      "Train Epoch: 6 [81920/143511 (57%)]\tLoss: 6.921833\n",
      "Train Epoch: 6 [83200/143511 (58%)]\tLoss: 6.047977\n",
      "Train Epoch: 6 [84480/143511 (59%)]\tLoss: 6.605289\n",
      "Train Epoch: 6 [85760/143511 (60%)]\tLoss: 5.488003\n",
      "Train Epoch: 6 [87040/143511 (61%)]\tLoss: 6.864873\n",
      "Train Epoch: 6 [88320/143511 (61%)]\tLoss: 7.076948\n",
      "Train Epoch: 6 [89600/143511 (62%)]\tLoss: 4.718153\n",
      "Train Epoch: 6 [90880/143511 (63%)]\tLoss: 5.918383\n",
      "Train Epoch: 6 [92160/143511 (64%)]\tLoss: 5.297594\n",
      "Train Epoch: 6 [93440/143511 (65%)]\tLoss: 6.189634\n",
      "Train Epoch: 6 [94720/143511 (66%)]\tLoss: 5.071195\n",
      "Train Epoch: 6 [96000/143511 (67%)]\tLoss: 7.324988\n",
      "Train Epoch: 6 [97280/143511 (68%)]\tLoss: 4.879649\n",
      "Train Epoch: 6 [98560/143511 (69%)]\tLoss: 6.850123\n",
      "Train Epoch: 6 [99840/143511 (70%)]\tLoss: 6.288666\n",
      "Train Epoch: 6 [101120/143511 (70%)]\tLoss: 5.308801\n",
      "Train Epoch: 6 [102400/143511 (71%)]\tLoss: 5.351529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [103680/143511 (72%)]\tLoss: 6.295475\n",
      "Train Epoch: 6 [104960/143511 (73%)]\tLoss: 6.639312\n",
      "Train Epoch: 6 [106240/143511 (74%)]\tLoss: 4.707234\n",
      "Train Epoch: 6 [107520/143511 (75%)]\tLoss: 6.299406\n",
      "Train Epoch: 6 [108800/143511 (76%)]\tLoss: 6.815423\n",
      "Train Epoch: 6 [110080/143511 (77%)]\tLoss: 6.118813\n",
      "Train Epoch: 6 [111360/143511 (78%)]\tLoss: 5.840068\n",
      "Train Epoch: 6 [112640/143511 (78%)]\tLoss: 5.129815\n",
      "Train Epoch: 6 [113920/143511 (79%)]\tLoss: 5.828417\n",
      "Train Epoch: 6 [115200/143511 (80%)]\tLoss: 5.385818\n",
      "Train Epoch: 6 [116480/143511 (81%)]\tLoss: 7.631042\n",
      "Train Epoch: 6 [117760/143511 (82%)]\tLoss: 7.041106\n",
      "Train Epoch: 6 [119040/143511 (83%)]\tLoss: 6.305265\n",
      "Train Epoch: 6 [120320/143511 (84%)]\tLoss: 5.645521\n",
      "Train Epoch: 6 [121600/143511 (85%)]\tLoss: 7.478806\n",
      "Train Epoch: 6 [122880/143511 (86%)]\tLoss: 5.422095\n",
      "Train Epoch: 6 [124160/143511 (86%)]\tLoss: 6.205401\n",
      "Train Epoch: 6 [125440/143511 (87%)]\tLoss: 5.574083\n",
      "Train Epoch: 6 [126720/143511 (88%)]\tLoss: 7.215813\n",
      "Train Epoch: 6 [128000/143511 (89%)]\tLoss: 6.872693\n",
      "Train Epoch: 6 [129280/143511 (90%)]\tLoss: 6.392772\n",
      "Train Epoch: 6 [130560/143511 (91%)]\tLoss: 6.327231\n",
      "Train Epoch: 6 [131840/143511 (92%)]\tLoss: 6.535314\n",
      "Train Epoch: 6 [133120/143511 (93%)]\tLoss: 5.046286\n",
      "Train Epoch: 6 [134400/143511 (94%)]\tLoss: 6.301914\n",
      "Train Epoch: 6 [135680/143511 (94%)]\tLoss: 5.981293\n",
      "Train Epoch: 6 [136960/143511 (95%)]\tLoss: 5.994615\n",
      "Train Epoch: 6 [138240/143511 (96%)]\tLoss: 5.223926\n",
      "Train Epoch: 6 [139520/143511 (97%)]\tLoss: 6.622772\n",
      "Train Epoch: 6 [140800/143511 (98%)]\tLoss: 6.169578\n",
      "Train Epoch: 6 [142080/143511 (99%)]\tLoss: 6.224366\n",
      "Train Epoch: 6 [143360/143511 (100%)]\tLoss: 5.570116\n",
      "====> Epoch: 6 Average loss: 6.1812\n",
      "Train Epoch: 7 [0/143511 (0%)]\tLoss: 4.700077\n",
      "Train Epoch: 7 [1280/143511 (1%)]\tLoss: 6.841780\n",
      "Train Epoch: 7 [2560/143511 (2%)]\tLoss: 4.623624\n",
      "Train Epoch: 7 [3840/143511 (3%)]\tLoss: 6.838259\n",
      "Train Epoch: 7 [5120/143511 (4%)]\tLoss: 8.222730\n",
      "Train Epoch: 7 [6400/143511 (4%)]\tLoss: 5.047609\n",
      "Train Epoch: 7 [7680/143511 (5%)]\tLoss: 5.786362\n",
      "Train Epoch: 7 [8960/143511 (6%)]\tLoss: 6.565566\n",
      "Train Epoch: 7 [10240/143511 (7%)]\tLoss: 5.957005\n",
      "Train Epoch: 7 [11520/143511 (8%)]\tLoss: 6.392308\n",
      "Train Epoch: 7 [12800/143511 (9%)]\tLoss: 8.037168\n",
      "Train Epoch: 7 [14080/143511 (10%)]\tLoss: 5.076386\n",
      "Train Epoch: 7 [15360/143511 (11%)]\tLoss: 6.978826\n",
      "Train Epoch: 7 [16640/143511 (12%)]\tLoss: 6.274173\n",
      "Train Epoch: 7 [17920/143511 (12%)]\tLoss: 5.752681\n",
      "Train Epoch: 7 [19200/143511 (13%)]\tLoss: 5.361187\n",
      "Train Epoch: 7 [20480/143511 (14%)]\tLoss: 5.664391\n",
      "Train Epoch: 7 [21760/143511 (15%)]\tLoss: 6.492312\n",
      "Train Epoch: 7 [23040/143511 (16%)]\tLoss: 6.122971\n",
      "Train Epoch: 7 [24320/143511 (17%)]\tLoss: 4.841694\n",
      "Train Epoch: 7 [25600/143511 (18%)]\tLoss: 6.323290\n",
      "Train Epoch: 7 [26880/143511 (19%)]\tLoss: 7.122195\n",
      "Train Epoch: 7 [28160/143511 (20%)]\tLoss: 5.752561\n",
      "Train Epoch: 7 [29440/143511 (20%)]\tLoss: 6.840910\n",
      "Train Epoch: 7 [30720/143511 (21%)]\tLoss: 6.250891\n",
      "Train Epoch: 7 [32000/143511 (22%)]\tLoss: 5.008128\n",
      "Train Epoch: 7 [33280/143511 (23%)]\tLoss: 6.389008\n",
      "Train Epoch: 7 [34560/143511 (24%)]\tLoss: 6.638741\n",
      "Train Epoch: 7 [35840/143511 (25%)]\tLoss: 5.446353\n",
      "Train Epoch: 7 [37120/143511 (26%)]\tLoss: 7.467849\n",
      "Train Epoch: 7 [38400/143511 (27%)]\tLoss: 5.650702\n",
      "Train Epoch: 7 [39680/143511 (28%)]\tLoss: 7.151114\n",
      "Train Epoch: 7 [40960/143511 (29%)]\tLoss: 5.300590\n",
      "Train Epoch: 7 [42240/143511 (29%)]\tLoss: 6.582881\n",
      "Train Epoch: 7 [43520/143511 (30%)]\tLoss: 5.556211\n",
      "Train Epoch: 7 [44800/143511 (31%)]\tLoss: 6.251490\n",
      "Train Epoch: 7 [46080/143511 (32%)]\tLoss: 6.761915\n",
      "Train Epoch: 7 [47360/143511 (33%)]\tLoss: 6.034262\n",
      "Train Epoch: 7 [48640/143511 (34%)]\tLoss: 5.675496\n",
      "Train Epoch: 7 [49920/143511 (35%)]\tLoss: 5.191661\n",
      "Train Epoch: 7 [51200/143511 (36%)]\tLoss: 5.362276\n",
      "Train Epoch: 7 [52480/143511 (37%)]\tLoss: 6.546018\n",
      "Train Epoch: 7 [53760/143511 (37%)]\tLoss: 6.091167\n",
      "Train Epoch: 7 [55040/143511 (38%)]\tLoss: 6.692271\n",
      "Train Epoch: 7 [56320/143511 (39%)]\tLoss: 6.019013\n",
      "Train Epoch: 7 [57600/143511 (40%)]\tLoss: 6.380486\n",
      "Train Epoch: 7 [58880/143511 (41%)]\tLoss: 6.635800\n",
      "Train Epoch: 7 [60160/143511 (42%)]\tLoss: 5.183476\n",
      "Train Epoch: 7 [61440/143511 (43%)]\tLoss: 6.971398\n",
      "Train Epoch: 7 [62720/143511 (44%)]\tLoss: 6.371276\n",
      "Train Epoch: 7 [64000/143511 (45%)]\tLoss: 6.457532\n",
      "Train Epoch: 7 [65280/143511 (45%)]\tLoss: 6.587539\n",
      "Train Epoch: 7 [66560/143511 (46%)]\tLoss: 5.914176\n",
      "Train Epoch: 7 [67840/143511 (47%)]\tLoss: 4.766098\n",
      "Train Epoch: 7 [69120/143511 (48%)]\tLoss: 6.993720\n",
      "Train Epoch: 7 [70400/143511 (49%)]\tLoss: 7.077575\n",
      "Train Epoch: 7 [71680/143511 (50%)]\tLoss: 6.369810\n",
      "Train Epoch: 7 [72960/143511 (51%)]\tLoss: 7.076867\n",
      "Train Epoch: 7 [74240/143511 (52%)]\tLoss: 6.862585\n",
      "Train Epoch: 7 [75520/143511 (53%)]\tLoss: 6.572353\n",
      "Train Epoch: 7 [76800/143511 (53%)]\tLoss: 5.601066\n",
      "Train Epoch: 7 [78080/143511 (54%)]\tLoss: 7.117975\n",
      "Train Epoch: 7 [79360/143511 (55%)]\tLoss: 4.803092\n",
      "Train Epoch: 7 [80640/143511 (56%)]\tLoss: 6.270048\n",
      "Train Epoch: 7 [81920/143511 (57%)]\tLoss: 7.188889\n",
      "Train Epoch: 7 [83200/143511 (58%)]\tLoss: 6.820937\n",
      "Train Epoch: 7 [84480/143511 (59%)]\tLoss: 6.154232\n",
      "Train Epoch: 7 [85760/143511 (60%)]\tLoss: 6.960649\n",
      "Train Epoch: 7 [87040/143511 (61%)]\tLoss: 6.774420\n",
      "Train Epoch: 7 [88320/143511 (61%)]\tLoss: 5.571675\n",
      "Train Epoch: 7 [89600/143511 (62%)]\tLoss: 6.896823\n",
      "Train Epoch: 7 [90880/143511 (63%)]\tLoss: 6.819242\n",
      "Train Epoch: 7 [92160/143511 (64%)]\tLoss: 6.196655\n",
      "Train Epoch: 7 [93440/143511 (65%)]\tLoss: 6.547418\n",
      "Train Epoch: 7 [94720/143511 (66%)]\tLoss: 5.476479\n",
      "Train Epoch: 7 [96000/143511 (67%)]\tLoss: 6.730879\n",
      "Train Epoch: 7 [97280/143511 (68%)]\tLoss: 6.502542\n",
      "Train Epoch: 7 [98560/143511 (69%)]\tLoss: 6.428755\n",
      "Train Epoch: 7 [99840/143511 (70%)]\tLoss: 6.322377\n",
      "Train Epoch: 7 [101120/143511 (70%)]\tLoss: 6.154759\n",
      "Train Epoch: 7 [102400/143511 (71%)]\tLoss: 6.105670\n",
      "Train Epoch: 7 [103680/143511 (72%)]\tLoss: 6.000721\n",
      "Train Epoch: 7 [104960/143511 (73%)]\tLoss: 5.692727\n",
      "Train Epoch: 7 [106240/143511 (74%)]\tLoss: 5.243118\n",
      "Train Epoch: 7 [107520/143511 (75%)]\tLoss: 6.308867\n",
      "Train Epoch: 7 [108800/143511 (76%)]\tLoss: 6.253193\n",
      "Train Epoch: 7 [110080/143511 (77%)]\tLoss: 6.269440\n",
      "Train Epoch: 7 [111360/143511 (78%)]\tLoss: 5.980592\n",
      "Train Epoch: 7 [112640/143511 (78%)]\tLoss: 6.494740\n",
      "Train Epoch: 7 [113920/143511 (79%)]\tLoss: 6.076622\n",
      "Train Epoch: 7 [115200/143511 (80%)]\tLoss: 5.381240\n",
      "Train Epoch: 7 [116480/143511 (81%)]\tLoss: 6.838213\n",
      "Train Epoch: 7 [117760/143511 (82%)]\tLoss: 5.851764\n",
      "Train Epoch: 7 [119040/143511 (83%)]\tLoss: 6.189916\n",
      "Train Epoch: 7 [120320/143511 (84%)]\tLoss: 6.379267\n",
      "Train Epoch: 7 [121600/143511 (85%)]\tLoss: 5.626212\n",
      "Train Epoch: 7 [122880/143511 (86%)]\tLoss: 6.467701\n",
      "Train Epoch: 7 [124160/143511 (86%)]\tLoss: 5.454655\n",
      "Train Epoch: 7 [125440/143511 (87%)]\tLoss: 5.399642\n",
      "Train Epoch: 7 [126720/143511 (88%)]\tLoss: 4.921042\n",
      "Train Epoch: 7 [128000/143511 (89%)]\tLoss: 5.604591\n",
      "Train Epoch: 7 [129280/143511 (90%)]\tLoss: 5.989926\n",
      "Train Epoch: 7 [130560/143511 (91%)]\tLoss: 4.782413\n",
      "Train Epoch: 7 [131840/143511 (92%)]\tLoss: 5.023413\n",
      "Train Epoch: 7 [133120/143511 (93%)]\tLoss: 7.059162\n",
      "Train Epoch: 7 [134400/143511 (94%)]\tLoss: 5.662619\n",
      "Train Epoch: 7 [135680/143511 (94%)]\tLoss: 5.214520\n",
      "Train Epoch: 7 [136960/143511 (95%)]\tLoss: 6.003823\n",
      "Train Epoch: 7 [138240/143511 (96%)]\tLoss: 5.117968\n",
      "Train Epoch: 7 [139520/143511 (97%)]\tLoss: 6.891980\n",
      "Train Epoch: 7 [140800/143511 (98%)]\tLoss: 6.877269\n",
      "Train Epoch: 7 [142080/143511 (99%)]\tLoss: 6.091710\n",
      "Train Epoch: 7 [143360/143511 (100%)]\tLoss: 5.559125\n",
      "====> Epoch: 7 Average loss: 6.1543\n",
      "Train Epoch: 8 [0/143511 (0%)]\tLoss: 5.532022\n",
      "Train Epoch: 8 [1280/143511 (1%)]\tLoss: 5.855565\n",
      "Train Epoch: 8 [2560/143511 (2%)]\tLoss: 6.723323\n",
      "Train Epoch: 8 [3840/143511 (3%)]\tLoss: 5.849487\n",
      "Train Epoch: 8 [5120/143511 (4%)]\tLoss: 6.600516\n",
      "Train Epoch: 8 [6400/143511 (4%)]\tLoss: 6.905674\n",
      "Train Epoch: 8 [7680/143511 (5%)]\tLoss: 6.847542\n",
      "Train Epoch: 8 [8960/143511 (6%)]\tLoss: 5.390478\n",
      "Train Epoch: 8 [10240/143511 (7%)]\tLoss: 6.804567\n",
      "Train Epoch: 8 [11520/143511 (8%)]\tLoss: 7.445002\n",
      "Train Epoch: 8 [12800/143511 (9%)]\tLoss: 7.360049\n",
      "Train Epoch: 8 [14080/143511 (10%)]\tLoss: 6.202387\n",
      "Train Epoch: 8 [15360/143511 (11%)]\tLoss: 5.998951\n",
      "Train Epoch: 8 [16640/143511 (12%)]\tLoss: 6.290685\n",
      "Train Epoch: 8 [17920/143511 (12%)]\tLoss: 5.577471\n",
      "Train Epoch: 8 [19200/143511 (13%)]\tLoss: 5.302564\n",
      "Train Epoch: 8 [20480/143511 (14%)]\tLoss: 5.765603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [21760/143511 (15%)]\tLoss: 5.798108\n",
      "Train Epoch: 8 [23040/143511 (16%)]\tLoss: 5.137659\n",
      "Train Epoch: 8 [24320/143511 (17%)]\tLoss: 5.713527\n",
      "Train Epoch: 8 [25600/143511 (18%)]\tLoss: 5.332899\n",
      "Train Epoch: 8 [26880/143511 (19%)]\tLoss: 5.290483\n",
      "Train Epoch: 8 [28160/143511 (20%)]\tLoss: 5.852433\n",
      "Train Epoch: 8 [29440/143511 (20%)]\tLoss: 5.082150\n",
      "Train Epoch: 8 [30720/143511 (21%)]\tLoss: 5.288410\n",
      "Train Epoch: 8 [32000/143511 (22%)]\tLoss: 5.397590\n",
      "Train Epoch: 8 [33280/143511 (23%)]\tLoss: 6.288931\n",
      "Train Epoch: 8 [34560/143511 (24%)]\tLoss: 6.645655\n",
      "Train Epoch: 8 [35840/143511 (25%)]\tLoss: 6.538800\n",
      "Train Epoch: 8 [37120/143511 (26%)]\tLoss: 6.336383\n",
      "Train Epoch: 8 [38400/143511 (27%)]\tLoss: 6.117859\n",
      "Train Epoch: 8 [39680/143511 (28%)]\tLoss: 6.249860\n",
      "Train Epoch: 8 [40960/143511 (29%)]\tLoss: 6.994263\n",
      "Train Epoch: 8 [42240/143511 (29%)]\tLoss: 5.209042\n",
      "Train Epoch: 8 [43520/143511 (30%)]\tLoss: 5.772225\n",
      "Train Epoch: 8 [44800/143511 (31%)]\tLoss: 6.154293\n",
      "Train Epoch: 8 [46080/143511 (32%)]\tLoss: 6.752608\n",
      "Train Epoch: 8 [47360/143511 (33%)]\tLoss: 5.504623\n",
      "Train Epoch: 8 [48640/143511 (34%)]\tLoss: 8.081827\n",
      "Train Epoch: 8 [49920/143511 (35%)]\tLoss: 6.678168\n",
      "Train Epoch: 8 [51200/143511 (36%)]\tLoss: 6.416477\n",
      "Train Epoch: 8 [52480/143511 (37%)]\tLoss: 5.537648\n",
      "Train Epoch: 8 [53760/143511 (37%)]\tLoss: 5.788190\n",
      "Train Epoch: 8 [55040/143511 (38%)]\tLoss: 5.727738\n",
      "Train Epoch: 8 [56320/143511 (39%)]\tLoss: 5.828956\n",
      "Train Epoch: 8 [57600/143511 (40%)]\tLoss: 4.379664\n",
      "Train Epoch: 8 [58880/143511 (41%)]\tLoss: 6.008832\n",
      "Train Epoch: 8 [60160/143511 (42%)]\tLoss: 8.046562\n",
      "Train Epoch: 8 [61440/143511 (43%)]\tLoss: 5.858312\n",
      "Train Epoch: 8 [62720/143511 (44%)]\tLoss: 5.708945\n",
      "Train Epoch: 8 [64000/143511 (45%)]\tLoss: 5.725780\n",
      "Train Epoch: 8 [65280/143511 (45%)]\tLoss: 6.013079\n",
      "Train Epoch: 8 [66560/143511 (46%)]\tLoss: 6.457381\n",
      "Train Epoch: 8 [67840/143511 (47%)]\tLoss: 6.786323\n",
      "Train Epoch: 8 [69120/143511 (48%)]\tLoss: 5.829781\n",
      "Train Epoch: 8 [70400/143511 (49%)]\tLoss: 5.781858\n",
      "Train Epoch: 8 [71680/143511 (50%)]\tLoss: 6.417823\n",
      "Train Epoch: 8 [72960/143511 (51%)]\tLoss: 5.866618\n",
      "Train Epoch: 8 [74240/143511 (52%)]\tLoss: 5.561745\n",
      "Train Epoch: 8 [75520/143511 (53%)]\tLoss: 6.775065\n",
      "Train Epoch: 8 [76800/143511 (53%)]\tLoss: 5.436614\n",
      "Train Epoch: 8 [78080/143511 (54%)]\tLoss: 5.909330\n",
      "Train Epoch: 8 [79360/143511 (55%)]\tLoss: 6.046752\n",
      "Train Epoch: 8 [80640/143511 (56%)]\tLoss: 5.423403\n",
      "Train Epoch: 8 [81920/143511 (57%)]\tLoss: 7.444690\n",
      "Train Epoch: 8 [83200/143511 (58%)]\tLoss: 5.923179\n",
      "Train Epoch: 8 [84480/143511 (59%)]\tLoss: 5.949164\n",
      "Train Epoch: 8 [85760/143511 (60%)]\tLoss: 6.946942\n",
      "Train Epoch: 8 [87040/143511 (61%)]\tLoss: 7.008369\n",
      "Train Epoch: 8 [88320/143511 (61%)]\tLoss: 5.966919\n",
      "Train Epoch: 8 [89600/143511 (62%)]\tLoss: 5.767811\n",
      "Train Epoch: 8 [90880/143511 (63%)]\tLoss: 5.210804\n",
      "Train Epoch: 8 [92160/143511 (64%)]\tLoss: 6.143795\n",
      "Train Epoch: 8 [93440/143511 (65%)]\tLoss: 6.012923\n",
      "Train Epoch: 8 [94720/143511 (66%)]\tLoss: 5.462146\n",
      "Train Epoch: 8 [96000/143511 (67%)]\tLoss: 6.330792\n",
      "Train Epoch: 8 [97280/143511 (68%)]\tLoss: 5.607259\n",
      "Train Epoch: 8 [98560/143511 (69%)]\tLoss: 6.119664\n",
      "Train Epoch: 8 [99840/143511 (70%)]\tLoss: 5.834130\n",
      "Train Epoch: 8 [101120/143511 (70%)]\tLoss: 6.094275\n",
      "Train Epoch: 8 [102400/143511 (71%)]\tLoss: 5.345746\n",
      "Train Epoch: 8 [103680/143511 (72%)]\tLoss: 5.745534\n",
      "Train Epoch: 8 [104960/143511 (73%)]\tLoss: 7.090624\n",
      "Train Epoch: 8 [106240/143511 (74%)]\tLoss: 6.538174\n",
      "Train Epoch: 8 [107520/143511 (75%)]\tLoss: 5.896381\n",
      "Train Epoch: 8 [108800/143511 (76%)]\tLoss: 5.608603\n",
      "Train Epoch: 8 [110080/143511 (77%)]\tLoss: 6.509099\n",
      "Train Epoch: 8 [111360/143511 (78%)]\tLoss: 6.833909\n",
      "Train Epoch: 8 [112640/143511 (78%)]\tLoss: 6.117035\n",
      "Train Epoch: 8 [113920/143511 (79%)]\tLoss: 6.205033\n",
      "Train Epoch: 8 [115200/143511 (80%)]\tLoss: 6.069138\n",
      "Train Epoch: 8 [116480/143511 (81%)]\tLoss: 5.914540\n",
      "Train Epoch: 8 [117760/143511 (82%)]\tLoss: 6.337384\n",
      "Train Epoch: 8 [119040/143511 (83%)]\tLoss: 5.926658\n",
      "Train Epoch: 8 [120320/143511 (84%)]\tLoss: 5.436713\n",
      "Train Epoch: 8 [121600/143511 (85%)]\tLoss: 6.862180\n",
      "Train Epoch: 8 [122880/143511 (86%)]\tLoss: 6.061672\n",
      "Train Epoch: 8 [124160/143511 (86%)]\tLoss: 5.678628\n",
      "Train Epoch: 8 [125440/143511 (87%)]\tLoss: 6.317060\n",
      "Train Epoch: 8 [126720/143511 (88%)]\tLoss: 4.996472\n",
      "Train Epoch: 8 [128000/143511 (89%)]\tLoss: 5.592788\n",
      "Train Epoch: 8 [129280/143511 (90%)]\tLoss: 7.078309\n",
      "Train Epoch: 8 [130560/143511 (91%)]\tLoss: 5.184154\n",
      "Train Epoch: 8 [131840/143511 (92%)]\tLoss: 6.195931\n",
      "Train Epoch: 8 [133120/143511 (93%)]\tLoss: 5.731838\n",
      "Train Epoch: 8 [134400/143511 (94%)]\tLoss: 6.399422\n",
      "Train Epoch: 8 [135680/143511 (94%)]\tLoss: 7.915120\n",
      "Train Epoch: 8 [136960/143511 (95%)]\tLoss: 5.342564\n",
      "Train Epoch: 8 [138240/143511 (96%)]\tLoss: 6.517923\n",
      "Train Epoch: 8 [139520/143511 (97%)]\tLoss: 5.558751\n",
      "Train Epoch: 8 [140800/143511 (98%)]\tLoss: 4.305230\n",
      "Train Epoch: 8 [142080/143511 (99%)]\tLoss: 6.101941\n",
      "Train Epoch: 8 [143360/143511 (100%)]\tLoss: 5.797943\n",
      "====> Epoch: 8 Average loss: 6.1409\n",
      "Train Epoch: 9 [0/143511 (0%)]\tLoss: 5.469810\n",
      "Train Epoch: 9 [1280/143511 (1%)]\tLoss: 7.766865\n",
      "Train Epoch: 9 [2560/143511 (2%)]\tLoss: 6.284963\n",
      "Train Epoch: 9 [3840/143511 (3%)]\tLoss: 5.839559\n",
      "Train Epoch: 9 [5120/143511 (4%)]\tLoss: 6.874621\n",
      "Train Epoch: 9 [6400/143511 (4%)]\tLoss: 7.183833\n",
      "Train Epoch: 9 [7680/143511 (5%)]\tLoss: 5.797220\n",
      "Train Epoch: 9 [8960/143511 (6%)]\tLoss: 5.610263\n",
      "Train Epoch: 9 [10240/143511 (7%)]\tLoss: 7.326380\n",
      "Train Epoch: 9 [11520/143511 (8%)]\tLoss: 5.480740\n",
      "Train Epoch: 9 [12800/143511 (9%)]\tLoss: 5.970470\n",
      "Train Epoch: 9 [14080/143511 (10%)]\tLoss: 6.254557\n",
      "Train Epoch: 9 [15360/143511 (11%)]\tLoss: 6.848442\n",
      "Train Epoch: 9 [16640/143511 (12%)]\tLoss: 6.693464\n",
      "Train Epoch: 9 [17920/143511 (12%)]\tLoss: 5.175148\n",
      "Train Epoch: 9 [19200/143511 (13%)]\tLoss: 6.812583\n",
      "Train Epoch: 9 [20480/143511 (14%)]\tLoss: 5.194705\n",
      "Train Epoch: 9 [21760/143511 (15%)]\tLoss: 6.902870\n",
      "Train Epoch: 9 [23040/143511 (16%)]\tLoss: 4.886797\n",
      "Train Epoch: 9 [24320/143511 (17%)]\tLoss: 5.894849\n",
      "Train Epoch: 9 [25600/143511 (18%)]\tLoss: 6.815732\n",
      "Train Epoch: 9 [26880/143511 (19%)]\tLoss: 5.782687\n",
      "Train Epoch: 9 [28160/143511 (20%)]\tLoss: 6.038507\n",
      "Train Epoch: 9 [29440/143511 (20%)]\tLoss: 5.346041\n",
      "Train Epoch: 9 [30720/143511 (21%)]\tLoss: 5.626782\n",
      "Train Epoch: 9 [32000/143511 (22%)]\tLoss: 6.067478\n",
      "Train Epoch: 9 [33280/143511 (23%)]\tLoss: 4.644904\n",
      "Train Epoch: 9 [34560/143511 (24%)]\tLoss: 6.210516\n",
      "Train Epoch: 9 [35840/143511 (25%)]\tLoss: 5.952812\n",
      "Train Epoch: 9 [37120/143511 (26%)]\tLoss: 6.287653\n",
      "Train Epoch: 9 [38400/143511 (27%)]\tLoss: 5.659988\n",
      "Train Epoch: 9 [39680/143511 (28%)]\tLoss: 5.766093\n",
      "Train Epoch: 9 [40960/143511 (29%)]\tLoss: 5.715598\n",
      "Train Epoch: 9 [42240/143511 (29%)]\tLoss: 6.769130\n",
      "Train Epoch: 9 [43520/143511 (30%)]\tLoss: 7.155959\n",
      "Train Epoch: 9 [44800/143511 (31%)]\tLoss: 5.339186\n",
      "Train Epoch: 9 [46080/143511 (32%)]\tLoss: 5.687107\n",
      "Train Epoch: 9 [47360/143511 (33%)]\tLoss: 5.993545\n",
      "Train Epoch: 9 [48640/143511 (34%)]\tLoss: 6.332866\n",
      "Train Epoch: 9 [49920/143511 (35%)]\tLoss: 5.921854\n",
      "Train Epoch: 9 [51200/143511 (36%)]\tLoss: 6.465762\n",
      "Train Epoch: 9 [52480/143511 (37%)]\tLoss: 6.526532\n",
      "Train Epoch: 9 [53760/143511 (37%)]\tLoss: 6.438606\n",
      "Train Epoch: 9 [55040/143511 (38%)]\tLoss: 5.990907\n",
      "Train Epoch: 9 [56320/143511 (39%)]\tLoss: 6.120566\n",
      "Train Epoch: 9 [57600/143511 (40%)]\tLoss: 5.060189\n",
      "Train Epoch: 9 [58880/143511 (41%)]\tLoss: 5.358833\n",
      "Train Epoch: 9 [60160/143511 (42%)]\tLoss: 5.555841\n",
      "Train Epoch: 9 [61440/143511 (43%)]\tLoss: 6.029569\n",
      "Train Epoch: 9 [62720/143511 (44%)]\tLoss: 6.678747\n",
      "Train Epoch: 9 [64000/143511 (45%)]\tLoss: 6.106896\n",
      "Train Epoch: 9 [65280/143511 (45%)]\tLoss: 6.320071\n",
      "Train Epoch: 9 [66560/143511 (46%)]\tLoss: 4.792263\n",
      "Train Epoch: 9 [67840/143511 (47%)]\tLoss: 5.596333\n",
      "Train Epoch: 9 [69120/143511 (48%)]\tLoss: 5.498430\n",
      "Train Epoch: 9 [70400/143511 (49%)]\tLoss: 6.603456\n",
      "Train Epoch: 9 [71680/143511 (50%)]\tLoss: 4.803751\n",
      "Train Epoch: 9 [72960/143511 (51%)]\tLoss: 5.358757\n",
      "Train Epoch: 9 [74240/143511 (52%)]\tLoss: 6.612505\n",
      "Train Epoch: 9 [75520/143511 (53%)]\tLoss: 6.260011\n",
      "Train Epoch: 9 [76800/143511 (53%)]\tLoss: 5.640919\n",
      "Train Epoch: 9 [78080/143511 (54%)]\tLoss: 6.056329\n",
      "Train Epoch: 9 [79360/143511 (55%)]\tLoss: 6.817320\n",
      "Train Epoch: 9 [80640/143511 (56%)]\tLoss: 6.707280\n",
      "Train Epoch: 9 [81920/143511 (57%)]\tLoss: 6.515080\n",
      "Train Epoch: 9 [83200/143511 (58%)]\tLoss: 4.946075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [84480/143511 (59%)]\tLoss: 4.895270\n",
      "Train Epoch: 9 [85760/143511 (60%)]\tLoss: 5.947866\n",
      "Train Epoch: 9 [87040/143511 (61%)]\tLoss: 6.249286\n",
      "Train Epoch: 9 [88320/143511 (61%)]\tLoss: 7.531250\n",
      "Train Epoch: 9 [89600/143511 (62%)]\tLoss: 5.687867\n",
      "Train Epoch: 9 [90880/143511 (63%)]\tLoss: 5.506376\n",
      "Train Epoch: 9 [92160/143511 (64%)]\tLoss: 5.833853\n",
      "Train Epoch: 9 [93440/143511 (65%)]\tLoss: 5.698204\n",
      "Train Epoch: 9 [94720/143511 (66%)]\tLoss: 6.559685\n",
      "Train Epoch: 9 [96000/143511 (67%)]\tLoss: 6.959698\n",
      "Train Epoch: 9 [97280/143511 (68%)]\tLoss: 5.089138\n",
      "Train Epoch: 9 [98560/143511 (69%)]\tLoss: 7.299997\n",
      "Train Epoch: 9 [99840/143511 (70%)]\tLoss: 5.046866\n",
      "Train Epoch: 9 [101120/143511 (70%)]\tLoss: 6.098492\n",
      "Train Epoch: 9 [102400/143511 (71%)]\tLoss: 6.345285\n",
      "Train Epoch: 9 [103680/143511 (72%)]\tLoss: 5.425423\n",
      "Train Epoch: 9 [104960/143511 (73%)]\tLoss: 6.797670\n",
      "Train Epoch: 9 [106240/143511 (74%)]\tLoss: 6.457715\n",
      "Train Epoch: 9 [107520/143511 (75%)]\tLoss: 7.965286\n",
      "Train Epoch: 9 [108800/143511 (76%)]\tLoss: 6.137995\n",
      "Train Epoch: 9 [110080/143511 (77%)]\tLoss: 6.948959\n",
      "Train Epoch: 9 [111360/143511 (78%)]\tLoss: 7.643048\n",
      "Train Epoch: 9 [112640/143511 (78%)]\tLoss: 5.510068\n",
      "Train Epoch: 9 [113920/143511 (79%)]\tLoss: 5.522007\n",
      "Train Epoch: 9 [115200/143511 (80%)]\tLoss: 5.566127\n",
      "Train Epoch: 9 [116480/143511 (81%)]\tLoss: 5.807468\n",
      "Train Epoch: 9 [117760/143511 (82%)]\tLoss: 5.459267\n",
      "Train Epoch: 9 [119040/143511 (83%)]\tLoss: 5.981254\n",
      "Train Epoch: 9 [120320/143511 (84%)]\tLoss: 7.721180\n",
      "Train Epoch: 9 [121600/143511 (85%)]\tLoss: 6.077796\n",
      "Train Epoch: 9 [122880/143511 (86%)]\tLoss: 5.502016\n",
      "Train Epoch: 9 [124160/143511 (86%)]\tLoss: 5.720580\n",
      "Train Epoch: 9 [125440/143511 (87%)]\tLoss: 6.060791\n",
      "Train Epoch: 9 [126720/143511 (88%)]\tLoss: 6.324021\n",
      "Train Epoch: 9 [128000/143511 (89%)]\tLoss: 6.145790\n",
      "Train Epoch: 9 [129280/143511 (90%)]\tLoss: 6.237160\n",
      "Train Epoch: 9 [130560/143511 (91%)]\tLoss: 6.883192\n",
      "Train Epoch: 9 [131840/143511 (92%)]\tLoss: 5.180941\n",
      "Train Epoch: 9 [133120/143511 (93%)]\tLoss: 6.519464\n",
      "Train Epoch: 9 [134400/143511 (94%)]\tLoss: 5.030731\n",
      "Train Epoch: 9 [135680/143511 (94%)]\tLoss: 6.828867\n",
      "Train Epoch: 9 [136960/143511 (95%)]\tLoss: 6.078740\n",
      "Train Epoch: 9 [138240/143511 (96%)]\tLoss: 6.386119\n",
      "Train Epoch: 9 [139520/143511 (97%)]\tLoss: 4.934112\n",
      "Train Epoch: 9 [140800/143511 (98%)]\tLoss: 4.927265\n",
      "Train Epoch: 9 [142080/143511 (99%)]\tLoss: 6.639971\n",
      "Train Epoch: 9 [143360/143511 (100%)]\tLoss: 5.567703\n",
      "====> Epoch: 9 Average loss: 6.1109\n",
      "Train Epoch: 10 [0/143511 (0%)]\tLoss: 6.317680\n",
      "Train Epoch: 10 [1280/143511 (1%)]\tLoss: 6.272705\n",
      "Train Epoch: 10 [2560/143511 (2%)]\tLoss: 5.521023\n",
      "Train Epoch: 10 [3840/143511 (3%)]\tLoss: 6.235267\n",
      "Train Epoch: 10 [5120/143511 (4%)]\tLoss: 6.254830\n",
      "Train Epoch: 10 [6400/143511 (4%)]\tLoss: 5.259947\n",
      "Train Epoch: 10 [7680/143511 (5%)]\tLoss: 6.460691\n",
      "Train Epoch: 10 [8960/143511 (6%)]\tLoss: 5.219679\n",
      "Train Epoch: 10 [10240/143511 (7%)]\tLoss: 6.099618\n",
      "Train Epoch: 10 [11520/143511 (8%)]\tLoss: 6.764775\n",
      "Train Epoch: 10 [12800/143511 (9%)]\tLoss: 7.475641\n",
      "Train Epoch: 10 [14080/143511 (10%)]\tLoss: 6.134377\n",
      "Train Epoch: 10 [15360/143511 (11%)]\tLoss: 6.227409\n",
      "Train Epoch: 10 [16640/143511 (12%)]\tLoss: 7.147873\n",
      "Train Epoch: 10 [17920/143511 (12%)]\tLoss: 5.731398\n",
      "Train Epoch: 10 [19200/143511 (13%)]\tLoss: 6.934682\n",
      "Train Epoch: 10 [20480/143511 (14%)]\tLoss: 6.585128\n",
      "Train Epoch: 10 [21760/143511 (15%)]\tLoss: 6.288980\n",
      "Train Epoch: 10 [23040/143511 (16%)]\tLoss: 6.287321\n",
      "Train Epoch: 10 [24320/143511 (17%)]\tLoss: 7.210418\n",
      "Train Epoch: 10 [25600/143511 (18%)]\tLoss: 7.232322\n",
      "Train Epoch: 10 [26880/143511 (19%)]\tLoss: 6.094368\n",
      "Train Epoch: 10 [28160/143511 (20%)]\tLoss: 7.005177\n",
      "Train Epoch: 10 [29440/143511 (20%)]\tLoss: 5.610819\n",
      "Train Epoch: 10 [30720/143511 (21%)]\tLoss: 6.141580\n",
      "Train Epoch: 10 [32000/143511 (22%)]\tLoss: 6.828747\n",
      "Train Epoch: 10 [33280/143511 (23%)]\tLoss: 6.357649\n",
      "Train Epoch: 10 [34560/143511 (24%)]\tLoss: 5.537739\n",
      "Train Epoch: 10 [35840/143511 (25%)]\tLoss: 5.784521\n",
      "Train Epoch: 10 [37120/143511 (26%)]\tLoss: 6.673440\n",
      "Train Epoch: 10 [38400/143511 (27%)]\tLoss: 5.548550\n",
      "Train Epoch: 10 [39680/143511 (28%)]\tLoss: 6.817745\n",
      "Train Epoch: 10 [40960/143511 (29%)]\tLoss: 6.121439\n",
      "Train Epoch: 10 [42240/143511 (29%)]\tLoss: 4.206265\n",
      "Train Epoch: 10 [43520/143511 (30%)]\tLoss: 6.813420\n",
      "Train Epoch: 10 [44800/143511 (31%)]\tLoss: 6.915398\n",
      "Train Epoch: 10 [46080/143511 (32%)]\tLoss: 6.952599\n",
      "Train Epoch: 10 [47360/143511 (33%)]\tLoss: 5.890125\n",
      "Train Epoch: 10 [48640/143511 (34%)]\tLoss: 5.941428\n",
      "Train Epoch: 10 [49920/143511 (35%)]\tLoss: 5.751797\n",
      "Train Epoch: 10 [51200/143511 (36%)]\tLoss: 6.630838\n",
      "Train Epoch: 10 [52480/143511 (37%)]\tLoss: 5.464821\n",
      "Train Epoch: 10 [53760/143511 (37%)]\tLoss: 5.677282\n",
      "Train Epoch: 10 [55040/143511 (38%)]\tLoss: 6.012535\n",
      "Train Epoch: 10 [56320/143511 (39%)]\tLoss: 4.838960\n",
      "Train Epoch: 10 [57600/143511 (40%)]\tLoss: 5.724211\n",
      "Train Epoch: 10 [58880/143511 (41%)]\tLoss: 7.494281\n",
      "Train Epoch: 10 [60160/143511 (42%)]\tLoss: 4.943122\n",
      "Train Epoch: 10 [61440/143511 (43%)]\tLoss: 6.718656\n",
      "Train Epoch: 10 [62720/143511 (44%)]\tLoss: 5.516538\n",
      "Train Epoch: 10 [64000/143511 (45%)]\tLoss: 6.019260\n",
      "Train Epoch: 10 [65280/143511 (45%)]\tLoss: 5.062391\n",
      "Train Epoch: 10 [66560/143511 (46%)]\tLoss: 6.954133\n",
      "Train Epoch: 10 [67840/143511 (47%)]\tLoss: 5.350984\n",
      "Train Epoch: 10 [69120/143511 (48%)]\tLoss: 5.688540\n",
      "Train Epoch: 10 [70400/143511 (49%)]\tLoss: 6.427755\n",
      "Train Epoch: 10 [71680/143511 (50%)]\tLoss: 6.210810\n",
      "Train Epoch: 10 [72960/143511 (51%)]\tLoss: 5.941620\n",
      "Train Epoch: 10 [74240/143511 (52%)]\tLoss: 5.677589\n",
      "Train Epoch: 10 [75520/143511 (53%)]\tLoss: 6.428221\n",
      "Train Epoch: 10 [76800/143511 (53%)]\tLoss: 6.775035\n",
      "Train Epoch: 10 [78080/143511 (54%)]\tLoss: 5.668169\n",
      "Train Epoch: 10 [79360/143511 (55%)]\tLoss: 5.429958\n",
      "Train Epoch: 10 [80640/143511 (56%)]\tLoss: 6.204411\n",
      "Train Epoch: 10 [81920/143511 (57%)]\tLoss: 5.437602\n",
      "Train Epoch: 10 [83200/143511 (58%)]\tLoss: 6.369905\n",
      "Train Epoch: 10 [84480/143511 (59%)]\tLoss: 4.626880\n",
      "Train Epoch: 10 [85760/143511 (60%)]\tLoss: 5.565080\n",
      "Train Epoch: 10 [87040/143511 (61%)]\tLoss: 5.401625\n",
      "Train Epoch: 10 [88320/143511 (61%)]\tLoss: 5.575481\n",
      "Train Epoch: 10 [89600/143511 (62%)]\tLoss: 5.136257\n",
      "Train Epoch: 10 [90880/143511 (63%)]\tLoss: 5.411875\n",
      "Train Epoch: 10 [92160/143511 (64%)]\tLoss: 6.034468\n",
      "Train Epoch: 10 [93440/143511 (65%)]\tLoss: 6.040511\n",
      "Train Epoch: 10 [94720/143511 (66%)]\tLoss: 4.518315\n",
      "Train Epoch: 10 [96000/143511 (67%)]\tLoss: 6.407925\n",
      "Train Epoch: 10 [97280/143511 (68%)]\tLoss: 5.507682\n",
      "Train Epoch: 10 [98560/143511 (69%)]\tLoss: 6.396475\n",
      "Train Epoch: 10 [99840/143511 (70%)]\tLoss: 6.808436\n",
      "Train Epoch: 10 [101120/143511 (70%)]\tLoss: 5.482387\n",
      "Train Epoch: 10 [102400/143511 (71%)]\tLoss: 4.089038\n",
      "Train Epoch: 10 [103680/143511 (72%)]\tLoss: 6.065325\n",
      "Train Epoch: 10 [104960/143511 (73%)]\tLoss: 6.859596\n",
      "Train Epoch: 10 [106240/143511 (74%)]\tLoss: 6.399725\n",
      "Train Epoch: 10 [107520/143511 (75%)]\tLoss: 6.993755\n",
      "Train Epoch: 10 [108800/143511 (76%)]\tLoss: 6.917616\n",
      "Train Epoch: 10 [110080/143511 (77%)]\tLoss: 6.645487\n",
      "Train Epoch: 10 [111360/143511 (78%)]\tLoss: 7.223145\n",
      "Train Epoch: 10 [112640/143511 (78%)]\tLoss: 6.188195\n",
      "Train Epoch: 10 [113920/143511 (79%)]\tLoss: 6.574526\n",
      "Train Epoch: 10 [115200/143511 (80%)]\tLoss: 6.462074\n",
      "Train Epoch: 10 [116480/143511 (81%)]\tLoss: 5.597759\n",
      "Train Epoch: 10 [117760/143511 (82%)]\tLoss: 6.945756\n",
      "Train Epoch: 10 [119040/143511 (83%)]\tLoss: 6.777762\n",
      "Train Epoch: 10 [120320/143511 (84%)]\tLoss: 6.308741\n",
      "Train Epoch: 10 [121600/143511 (85%)]\tLoss: 6.182775\n",
      "Train Epoch: 10 [122880/143511 (86%)]\tLoss: 5.277720\n",
      "Train Epoch: 10 [124160/143511 (86%)]\tLoss: 5.224641\n",
      "Train Epoch: 10 [125440/143511 (87%)]\tLoss: 7.184570\n",
      "Train Epoch: 10 [126720/143511 (88%)]\tLoss: 6.814741\n",
      "Train Epoch: 10 [128000/143511 (89%)]\tLoss: 5.614871\n",
      "Train Epoch: 10 [129280/143511 (90%)]\tLoss: 6.682188\n",
      "Train Epoch: 10 [130560/143511 (91%)]\tLoss: 6.580966\n",
      "Train Epoch: 10 [131840/143511 (92%)]\tLoss: 6.043321\n",
      "Train Epoch: 10 [133120/143511 (93%)]\tLoss: 5.908568\n",
      "Train Epoch: 10 [134400/143511 (94%)]\tLoss: 6.375168\n",
      "Train Epoch: 10 [135680/143511 (94%)]\tLoss: 5.613243\n",
      "Train Epoch: 10 [136960/143511 (95%)]\tLoss: 5.796387\n",
      "Train Epoch: 10 [138240/143511 (96%)]\tLoss: 7.445340\n",
      "Train Epoch: 10 [139520/143511 (97%)]\tLoss: 5.151799\n",
      "Train Epoch: 10 [140800/143511 (98%)]\tLoss: 5.919322\n",
      "Train Epoch: 10 [142080/143511 (99%)]\tLoss: 6.619367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [143360/143511 (100%)]\tLoss: 6.285866\n",
      "====> Epoch: 10 Average loss: 6.0967\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
